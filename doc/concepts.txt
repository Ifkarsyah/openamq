gdl
    title     = Concepts and Vision
    subtitle  = A Background to the AMQ Project
    product   = OpenAMQ
    author    = iMatix Corporation <amq@imatix.com>
    date      = 2005/05/05
    copyright = Copyright (c) 2004-2005 JPMorgan and iMatix Corporation
    version   = 0.9
end gdl

Introduction
************

Aim of this Document
====================

This is a general introduction to AMQ, intended for a technically-minded
readership. It explains the basic AMQ concepts, and goes into medium
detail on all significant aspects of the architecture and technology.

Seperate documents provide detailled guides to individual aspects of the
architecture and technology.

Advanced Message Queues
=======================

AMQ ("Advanced Message Queues") is a broad and long-term project with
the overall goal of creating commodity middleware for use in large-scale
business and financial applications. The AMQ project has these specific
short term goals:

1. To define an industry-standard wire-level protocol (AMQP).
2. To build a widely-usable reference implementation (OpenAMQ).

And these longer term goals:

1. To create a standard architecture for service-oriented networks.
2. To create a thriving open-source community (openamq.org).

What is "Middleware"?
=====================

"Middleware" is a generic term for software that interconnects systems.
We use the term specifically to mean software that passes messages
between applications. The key characteristics of middleware, as we
define it, are:

- Application-level messages: the objects passed across the network
  are meaningful to client applications.
- Queuing and routing: the middleware must be able to queue messages
  internally, and route them to different clients in various ways.
- Asynchronous operation: messages are pushed through the network
  as fast as possible, with queues acting to buffer slower parts of
  the network.
- Selectable service levels: the client applications can explicitly
  choose between different levels of speed and reliability.

An ideal middleware system must be able to:

- Handle all kinds of data, opaquely, and without preconceptions as
  to encoding or representation.
- Handle messages of any size up to multi-gigabytes.
- Handle both high-volume and high-reliability scenarios.  In the
  first case throughput is critical but messages can be lost.  In
  the latter case messages can never be lost, period.
- Provide several types of routing, including queues (where messages
  are distributed between consumers), pub/sub (where messages are
  published to as many susbcribers as ask for them), topics (where
  messages are published according to a hierarchy of names, and
  content-based routing (where messages are routed according to
  key field values).
- Work fully asynchronously so that clients do not poll for messages
  but receive data via callbacks or other asynchronous mechanisms.

And further:

- To interoperate with or simulate other middleware systems.
- To run well on all boxes, from small clients to large servers.
- To be cheap enough to deploy without licensing concerns.
- To be easily adapted, extended, and if necessary, repaired.

And finally:

- To allow the creation of an abstract network of services.
- To provide ways for application developers to add services to the
  network.
- To provide ways for replicating data throughout such a network.

While there exist several large commercial middleware systems that
provide all of the first set of requirements, there are no middleware
systems - commercial or open - that also provide the second set.  There
are of course many other requirements for any kind of server.

The basic plan for making middleware from scratch is this: we start by
making fast, reliable boxes that do the kinds of message passing we need.
We then organise these boxes into more and more sophisticated networks
by adding layers of services.  To put it tritely: we build AMQ using AMQ.

Open Source Middleware
======================

There is a fair amount of open source middleware. Mostly Java, mostly
implementations of existing standard middleware APIs such as CORBA and
JMS.

What is strikingly lacking in the open source middleware world is a
robust answer to the problems actually facing enterprise software
integration. There are no proposals for standard middleware protocols,
there are no attempts to build commodity middleware servers such as the
NSCA web server that became Apache.

The main reason is probably the gulf between the academic and small
open source teams, and the business world that builds systems large
enough to need serious middleware.

AMQ is, to our knowledge, the first attempt to solve this problem using
standards from the wire up to the application. As a project, it is long
overdue: middleware is the last significant slice of software
infrastructure that is still dominated by commercial vendor solutions
and not moving in any serious way towards commodity open source.

Using Middleware in Real Life
=============================

Scales of Deployment
--------------------

The scope of AMQ covers deployment at different levels of scale:

1. Developer/casual use: 1 server, 1 user, 10 queues, 1 message per
   second.

2. Production application: 2 servers, 10-100 users, 10-50 queues, 30
   messages per second (100K/hour).

3. Departmental mission critical application: 4 servers, 100-500 users,
   50-100 queues, 60 messages per second (250K/hour).

4. Regional mission critical application: 16 servers, 500-2,000 users,
   100-500 queues and topics, 250 messages per second (1M/hour).

5. Global mission critical application: 64 servers, 2K-10K users,
   500-1000 queues and topics, 2,500 messages per second (10M/hour).

6. Market data (trading): 200 servers, 5K users, 10K topics, 100K
   messages per second (360M/hour).

Extreme Scenario - Market Data
------------------------------

Market data is an extreme scenario at the upper-end of what we are
aiming for with AMQ. We have set the benchmark at 100,000 events per
second between a producer application and a consumer application. The
occasional dropped message is acceptable, but dropout should be
measurable.

To achieve this rate of messaging requires high-specification
hardware, gigabit networking and significant tuning at all levels.
Experience from existing projects shows that even OS context-switch
time becomes significant at this rate of messaging.  The topic space
for event notification should be able to handle 10,000 topics with
50% of traffic volume going through 10% of the topics and delivered
to 1,000 subscribers.

Challenges and Architectures
****************************

Designing a Successful Project
==============================

The AMQ project has had to face the same kinds of challenges that face
all projects: to deliver high-quality results in a relatively short time
and with a constrained budget.

Software projects tend to succeed or fail according to three main
criteria:

1. The quality and relevant experience of the team.
2. The competence of the client.
3. The leverage and transparency of the toolkit.

In every failing software project (anything up to 75% of all projects by
some estimates), one or more of these key criteria have failed. Most
often, the people involved in a failing project are simply not very
good. Often, they are forced to use unfamiliar or unstable technologies
for political reasons (management saw a nice presentation).

It is rare to see projects fail for purely budgetary or planning
reasons. The details of a project plan are far less important than
ensuring that the team can ask questions freely, receive competent
answers rapidly, and implement solutions with freedom of approach.

Tight deadlines and budgets can often improve the overall process by
uncovering problems earlier. This is, perhaps why "low-budget" movies
can often be so much better than well-financed affairs.

The General Solution
====================

It's a truism in software design that a general solution works better,
is easier to maintain, and is often cheaper than a specific solution.

So it goes with AMQ - at every level we have tried to ignore the
specifics of the problem to build general solutions. For example when
designing the AMQ protocol we decided to treat messages as opaque binary
MIME-typed blobs. This is more general than saying: "messages will be
XML documents that may encapsulate binary data".

Another example of generality: the tools we built to allow us to build
OpenAMQ are for the most part totally general and reusable tools.

A Commodity Platform
====================

A commodity product must use a commodity platform. That is, there is no
benefit in developing a commodity product that exotic dependencies.
OpenAMQ must be able to build and run on a simple box with little more
than a compatible compiler and standard libraries.

The platform we chose for our work was:

 - ANSI C (mainly dictated by the need for performance and stability)
 - A commodity OS: Linux, Solaris, or Win32 (dictated by our target
   users)
 - TCP/IP (at least initially)

There are many useful libraries that fit into this mix: PCRE (perl
compatible regular expressions), zlib, BDB (Berkeley DB), APR (Apache
Portable Runtime), and we have added these into our project as needed.

The use of commodity technology is not the same as the use of commodity
tools. We have made use of an extensive and sophisticated toolset, as
explained in a separate section of this document.

Portability
===========

Our target platforms are: Solaris, Linux, other POSIX boxes, and Win32.
By "portability" we mean that the same code packages will build and work
identically on all target platforms.

The iMatix approach to portability, defined in 1995 or so, is to put all
non-portable code into a separate library that can be tuned for specific
platforms.  Application code then becomes 100% portable, with none of
the conditional code that plagues most "portable" software.

The Apache project took a similar direction in 1999, building a portable
runtime.  Other projects such as Mozilla have done the same.

The OpenAMQ software uses both the Apache portable runtime, with some
patches (this layer is not entirely mature) and iMatix portability
libraries.

Protocol Design
===============

A good discussion of protocol design can be found in RFC 3117, "On the
Design of Application Protocols". The author of this RFC, Marshal T.
Rose, contributed several IETF standards, including a protocol framework
(BEEP, defined in RFC3080).

We did not use BEEP for AMQ, for several reasons: it uses XML wrapping
that we felt was unnecessary and it does not have an actively-developed
C implementation.

However, AMQP embodies many of the key design elements of BEEP. The main
challenges are:

1. How to negotiate new sessions, including encryption, protocols
   and versions, capabilities, etc.
2. How to frame requests on a connection (defining how each request
   starts and ends).
3. How to allow many requests to work asynchronously in parallel
   (multiplexing).
4. How to allow many outstanding requests (pipelining).
5. How to report success/failure.
6. How to implement a functional model, i.e. at what "level" the
   protocol should operate.

We discuss the specific chosen solution to each of these in the "AMQ
Protocol" section. In most cases our choice was driven by the desire to
make the most general-possible solution.

Quality and Standards
=====================

Our first step in starting the project was to define a standard for
defining standards, a document titled: "AMQ RFC001 - The OpenAMQ RFC
system." The second step was "AMQ RFC002 - C Coding Standards".

Hand-Written Code
-----------------

All programming needs to follow a strict style guide to remain readable.
Our style guide for ANSI C has been developed over some time, and is
remorselessly tuned for legibility. This is an extract from the RFC:

Spacing
.......

- Code should be formatted to fit an 80 character width terminal [may
  push that to at most 90 char width].
- Indent with 4 spaces, never use tabs.
- Spaces outside () and [], not inside.
- Space after commas.
- No space after -> or . in accessing pointers/structs.

Naming Conventions
..................

- All names are in English.
- Variable names are always lowercase with '_' as delimiter.
- Exported functions and variables are prefixed as lib_module_func.
- In rare cases, may abbreviate to lib_func.
- Macros are always capitalized.
- Type names end in _t,
- Functions or variables that are static to a single file are prefixed
  with s_,
- It is permissible to use short variable names within functions, as
  long as their definition is reasonably close to their place of
  use. (And functions should not be very long anyway.)
- Use xxx_nbr and xxx_ptr for local array indices and pointers in functions.
- Filenames are named lib_module.{c, h}.

Generated Code
--------------

GSL - the iMatix code generation language - is perhaps unique in that it
is deliberately designed to produce highly readable code. There are some
exceptions - for instance the code that implements the SMT state
machines is very fast and very ugly. The code that implements the iCL
classes is sometimes poorly-indented.

But in general the code generation frameworks that we use so extensively
produce code that a human programmer would be proud to write. Here is a
random fragment of code generated for an OpenAMQ class (this code does
topic publishing):

    /*  -------------------------------------------------------------------------
        amq_vhost_publish

        Type: Component method
        Accepts a amq_vhost_t reference and returns zero in case of success,
        1 in case of errors.
        Publishes a specified message to all interested subscribers in the
        virtual host.  Returns number of times message was published.  If the
        publish option is false, does not actually publish but only reports
        the number of susbcribers.
        -------------------------------------------------------------------------
    */

    int
        amq_vhost_publish (
        amq_vhost_t *  self,                /*  Reference to object              */
        char *   dest_name,                 /*  Topic destination name           */
        amq_smessage_t *  message,          /*  Message, if any                  */
        ipr_db_txn_t *  txn,                /*  Transaction, if any              */
        Bool     publish)                   /*  Actually publish message?        */
    {
        amq_subscr_t
            *subscr;                        /*  Subscriber object                */
        amq_match_t
            *match;                         /*  Match item                       */
        int
            subscr_nbr;
        int
            rc = 0;                         /*  Return code                      */

        assert (self);

        /*  Lookup topic name in match table, if found publish to subscribers    */
        match = amq_match_search (self->match_topics, dest_name);
        if (match) {
            for (IPR_BITS_EACH (subscr_nbr, match->bits)) {
                subscr = (amq_subscr_t *) self->subscr_index->data [subscr_nbr];
                if (subscr->no_local == FALSE
                ||  subscr->client_id != message->handle->client_id) {
                    if (publish)
                        amq_queue_publish (subscr->consumer->queue, message, txn);
                    rc++;
                }
            }
        }
        return (rc);
    }

The Server Architecture
=======================

What Makes a Fast, Reliable Server?
-----------------------------------

Apart from the obvious requirements of writing good code that is
reasonably efficient, the key to building a fast server is to reduce
the cost of servicing individual connections, and the key to
building a reliable server is to use finite state machines (FSMs).

Server Connection Handling
--------------------------

When iMatix began designing server toolkits in 1995, the classic model
was "one connection, one process", possibly with process pooling. This
model breaks-down rapidly, with a limit of 30-100 connections per server
(at which point system memory gets full).

We designed a single-process architecture (SMT) which uses
pseudo-threads (internally managed by the architecture, with no help
from the operating system) to eliminate process duplication. A server
built on this model (e.g. our Xitami web server) can handle hundreds or
thousands of connections with no serious impact on system memory.

When we reach several hundred connections, a new problem arises, namely
the use of system calls like "select" that involve linear searching. We
can use alternate system calls like "poll" that are more efficient, and
our current version of SMT does this. Servers built on this design are
rapid even with very many connections.

On larger boxes, however, a single-process server shows another
weakness: it cannot exploit multiple CPUs. Even the fastest
single-process server will be out-performed by a less efficient server
that can run on 4 or 8 CPUs.

Modern software uses multiple system threads to exploit multiple CPUs.
Operating systems like Linux are extremely good at scheduling threads
and switching between them.

Thus, a modern server must use multiple system threads. We are (as this
text is being written) modifying SMT to use a separate system thread per
pseudo-thread.

Finally, to handle very large numbers of connections (the so-called
"C10K problem"), we have to move to a more radical model still: a small
number of OS threads handling multiple connections, and a fully
asynchronous I/O model. A portable solution for this is somewhat beyond
the state of the art (e.g. the Linux 2.6 kernel supports asynch. I/O but
not for sockets), but we are developing a solution.

The predecessor to SMT, a pseudo multi-threading framework for OpenVMS
written in 1991 (and still used today) was entirely based on
asynchronous I/O and could handle 500-1000 connections on a modest
server.

Finite State Machines
---------------------

Underlying all these different I/O and threading models is a finite
state machine architecture. FSMs are particularly good for servers
because we can make them fully stable. That is, a well-designed FSM
handles errors so explicitly that the server never falls into the type
of ambiguities that generally cause failure.

Our FSM model is based on work done in several software engineering
tools (ETK, Libero) since 1985. The model is simple and generic, based
on this elementary design unit:

    state
        event -> next-state
            action

Where a state consists of 1 or more events, each which take the FSM to a
new 'next state', after executing zero or more actions. We add concepts
such as state and event inheritence, exception events, and called
states.

The core of the server consists of this state machine:

[amq_server_agent.png]

The source code of the state machine is an XML 'program'. Here is a
fragment of this code:

    <state name = "initialise connection">
        <event name = "ok" nextstate = "expect connection response">
            <action name = "read protocol header" />
            <action name = "check protocol header" />
            <action name = "send connection challenge" />
            <action name = "read next command" />
        </event>
        <event name = "connection error" nextstate = "">
            <action name = "close the connection" />
        </event>
    </state>

    <action name = "read protocol header">
        s_sock_read (thread, tcb->frame_header, 2);
    </action>

Note the ANSI C code wrapped inside XML tags. We use this technique
extensively in our code, as we describe later.

The server finite-state machine is explained in more detail in the
"OpenAMQ Server Architecture" document.

Server Classes
--------------

The server is built as a hierarchy of classes. The following figure
shows the way classes use each other. We show two types of usage,
classes that hold a single instance of another class, and classes that
act as containers for a set of child classes:

[server_classes.png]

We use the iCL framework to write the classes. This framework is
described in more detail later. Its advantage for our work is that we
can maintain a very formal organisation of code. The fact that iCL
generates huge amounts of perfect C code for free is useful too.

The server classes are explained in more detail in the "OpenAMQ Server
Architecture" document.

Client Architecture
===================

General Client Architecture
---------------------------

The OpenAMQ clients form a large part of the whole project.  In theory
we could make a full from-the-wire implementation for each programming
language - C, C++, Java, Perl, .NET, COM.

What we have chosen to do is to define a general architecture that can
be applied to all clients, and then to standardise and generate as
much of this as we can.

Our goal is that all OpenAMQ clients, whatever the language, use a
similar set of concepts and tools, and provide the application programmer
with a similar API.  This is not yet entirely the case.

The Framing Layer
.................

AMQP defines a set of commands that map onto frames (each command is a
specific frame).  The frames are formally defined in the amq_frames.xml
document.  For example:

    <frame name = "connection challenge">
        <field type = "octet"    name = "type"      value = "10" />
        <field type = "octet"    name = "version"   >Negotiated protocol version</field>
        <field type = "shortstr" name = "mechanisms">Available security mechanisms</field>
        <field type = "table"    name = "challenges">Challenge fields</field>
    </frame>

Using GSL code generation, it is a fairly simple matter to turn the
formal frame definitions into marshalling code.  We have done this in
C, Perl, Java.  This is a snippet of the generated C marshalling code:

    if (IS_CONNECTION_CHALLENGE (source)) {
        frame->type = FRAME_TYPE_CONNECTION_CHALLENGE;
        frame->body.connection_challenge.type = *source++;
        frame->body.connection_challenge.version = *source++;
        string_size = *source++;
        memcpy (frame->body.connection_challenge.mechanisms, source, string_size);
        frame->body.connection_challenge.mechanisms [string_size] = 0;
        source += string_size;
        GET_SHORT (string_size, source);
        frame->body.connection_challenge.challenges = ipr_longstr_new (source, string_size);
        source += string_size;
        frame->size = source - buffer;
    }

The framing layer is entirely generated.  The same XML specifications
are used in the server and in the clients, and to produce the AMQP
RFC specifications.  As well as eliminating a lot of redundant work,
this ensures that frame fields are consistently named in all our
AMQP implementations.

The Transport Layer
...................

The transport layer handles socket connections to the server, and reads
and writes raw frames.

This layer is specific to each language, and even in a single language
there may be several implementations.  For instance in C we have an SMT
implementation and a 'classic' implementation using OS threads.

The Protocol Layer
..................

The protocol layer consists of one or more FSMs, defining the connection
and channel states, and the valididity of frames in each state.  It must
also handle API requests ('methods') and their valididity in each state.

We are working to define a single set of "categorical" FSMs for the
protocol layer, in the same way as we have a single specification for
frames.  At present the FSMs are built by hand using different tools.
GSL lets one write an ad-hoc FSM generator in a few hours, so the real
cost is not the burden of maintaining extra tools, but of maintaining
multiple instances of what should be the same FSMs.

The External API
................

The Protocol Layer exports an API to the calling applications. This API
may itself be wrapped to provide something more familiar to nice
developers.

AMQ aims to be a standard and we also prefer to use existing standards
where possible.  In the middleware domain, the dominant standard is JMS,
the Java Messaging System, defined by Sun and large middleware vendors.

JMS has several strong advantages:

 - It is widely used and well-known, so supporting JMS means we gain
   instant credibility and entry into an existing skill pool.

 - JMS implements most mature middleware models.  Basically, if we can
   "do JMS", we satisfy a large portion of the market.

JMS has two serious disadvantages:

 - It is in principle licensed only for Java use.  We expect that it is
   possible to build a JMS-like API without falling foul of these license
   terms but we are not 100% certain at this stage.

 - JMS was designed with weaknesses.  This was, we think, a deliberate
   policy to maintain a gap between JMS providers and "real" middleware
   products.  All serious JMS implementations make their own extensions.
   JMS is not standard unless the developer stays away from these
   extensions.

Our goal is to support a JMS-like API.  In Java, this should look as close
to JMS as the JMS license and copyrights will allow.  In other languages,
we will use the same names and class hierachies.

We will have to extend JMS to fill the "gaps" in the specification and
to support functionality such as streaming that is specific to AMQP.

At the time of writing, we are still working on this API.  The existing
clients do not implement JMS but somewhat simpler, cleaner APIs.

Existing Client Implementations
-------------------------------

There are several different client architectures:

- A full general-use Java client.  This provides an API compatible with
  AMQ RFC014/0.1.  This client is built using a generated framing layer,
  FSMs for the protocol layer, and it uses Java streams for the transport
  layer.

- A full general-use ANSI C client.  This provides an API compatible with
  AMQ RFC014/0.1.  This client is built using a generated framing layer,
  FSMs for the protocol layer, and it uses OS multithreading over sockets
  for the transport layer.

- A COM client.  This client provides an API compatible with AMQ RFC015/0.4.
  It uses the synchronous SMT-based client (described below).

- An asynchronous kernel client in C.  (The "kernel" is the core library
  used to construct OpenAMQ.)  This uses the same technology as, and is
  designed to be integrated into, the OpenAMQ server.  It implements the
  AMQ RFC015/0.4 API.

- a synchronous kernel client in C.  This uses the OpenAMQ server
  technology but is intended for general use.

This are some FSM diagrams for the clients.  This is the asynchronous
kernel client:

[amq_aclient_agent.png]

This is the synchronous kernel client:

[amq_sclient_agent.png]

An Open Source Project
======================

Goals and Economics
-------------------

AMQ was conceived from the start as an open source product. This vision
is probably the most radical and defining aspect of the entire project.

The AMQ project, funded by a large institution and built by a specialist
engineering firm, represents a new way of building software systems.
As it grows, AMQ will draw support from many other institutions and
firms. To a large middleware consuming firm, even a significant investment
in such a project is much cheaper than the tangible cost of commercial
alternatives and the intangible costs of working with arbitrary,
incompatible, and closed systems.

The economics of the AMQ project are simple: every dollar spent on
creating this product will generate ten, a hundred dollars of value as
the cost of interconnecting applications comes down to zero, allowing
larger and more efficient software architectures.

Using proprietary infrastructure gives no advantages but rather many
disadvantages.

We believe that in a decade, this model of collaboration between large
software consumers and smaller open source producers will be commonplace,
even conventional.  Software is expensive to make, and open source is a
way - perhaps the only long-term way - to spread these costs effectively.

But in today's world, the sponsorship of AMQ by JPMorgan Chase is a bold
innovation.

How Open Source Works
---------------------

Open source, or free software, is a phenomenon that has arisen
spontaneously as the cost of communications has fallen over the last
decades.  One can almost say that as communications get cheaper,
programmers will tend to collaborate, building the tools they need,
then building infrastructure, then entire systems.

The attitude of commercial software producers towards this phenomenon
is mixed: some see open source as a fashion, a threat, or a left-wing
conspiracy.  Others see it as an opportunity.  It seems clear that
open source (or rather, the commoditization process that it represents)
splits the industry into two distinct halves: those who see the future
as a sea of cheap software supporting flottilas of services, and those
who make their money from selling expensive water.

While open source seems a somewhat chaotic, and definitely anarchic
process, and while asking ten open source developers "why they do it"
will result in twelve different answers, the mechanisms of the
process are, in my opinion, quite simple.

First, individual programmers always look to work on projects that
will maximise their opportunity for growth and new opportunities.
In a technical career, success comes from being an expert.  The best
programmers seek the hardest challenges.

Second, since the IT world is vast, and complex, and mostly filled
with junk (following Sturgeon's Law), smart programmers look for other
smart programmers with whom to work, and (importantly) against whom
to compete.  It is not possible to measure one's success in a vacuum,
nor in a crowd.

Third, the cheaper that communications become, the easier it is for
these smart programmers to find each other, work together on small
projects, and collaborate over long periods of time on larger
projects.  Cheap communications bring people together.

Fourth, when a group of elite programmers get together, they start to
look for "interesting" challenges to work on.  Long before open source
became an obvious trend, there were many very successful collaborative
projects.  Most of these filled niches: fractint, the Scandinavian
"demo" culture, emacs.  In each case competition with other projects
was a key driver.

The Internet boom that started in the mid-1990's pushed this process
exponentially.

So open source developers are mainly an elite - the very best
programmers - who enjoy working on the cutting edges of IT, where there
is an active R&D process, risk, and potentially huge reward.  They
compete to build the most elegant, and the most useful, structures.

Open source / free software (as compared to other types of collaborative
project) is particularly effective because every improvement is added
back into the process.  There is no proof as yet, but I'd argue that
the GPL license creates better software, faster, than the BSD license,
because of this effect.

Open Source as an Economy
-------------------------

A common misconception about open source is that because it is "free"
it is somehow a charity operation where programmers work bene-vola
because they want "to contribute".

This is totally wrong.  When Adam Smith said: "It is not from the
benevolence of the butcher, the brewer, or the baker, that we expect
our dinner, but from their regard to their own interest", he was
accurately describing a world in which self-interest creates
mutually-beneficial structures.

Open source contributors are attracted for different reasons, depending
on how far they understand and identify with the technology at hand.
We can identify the self-interest of each role, while seeing that the
overall structure serves everyone:

- "users" will evangelise (seeking security in the company of others
  using the same technology).

- "expert users" will help others who have problems (seeking the kudos
  that comes from helping others).

- "pundits" will discuss the technology in public forums (seeking the
  fame that comes from being able to accurately identify trends and
  future winners).

- "insiders" will take on parts of the testing process (seeking better
  familiarity with a technology that may become an important part of
  their skill set).

- "players" will delve into the technology itself, taking on smaller
  roles in the process (seeking the kudos and fame that can come from
  being on a winning team).

- "key players" will take on major roles in the project (seeking to
  impose their ideas, turn a small project into a major success, or
  otherwise earn a global reputation).

- "patrons" will provide financial support to the project (looking to
  sell services, often to the users, that require the technology to
  succeed and be widely used).

The naive view of open source focuses only on the players, ignoring
the wider economy of interests.  A successful open source project must
attract and support all these classes of people (and others, such as
the "troll", who vocally attacks the project in public forums, thus
stiffening the resolve of the users and pundits who defend it).

Thus we can understand the needs of each role:

- users need a pleasant and impressive product so they can feel proud
  about showing it to others.

- expert users need forums and mailing lists where they can answer
  questions.

- pundits need pre-packaged press releases, insider tips, and the
  occasional free lunch.  Some controversy also helps.

- insiders need regular releases, frequent improvements, and forums
  where they can propose ideas for the project.

- players need extension frameworks where they can write their (often
  sub-standard) code without affecting the primary project.

- key players need badges of membership, and access to the right
  tools and support.

- patrons need a high-quality functional product that supports their
  services and additional products.

The only people working full time, and usually professionally, on an
open source project are the key players.  All the others will take
part in the project as a side-effect of their on-going work or hobbies.

While a traditional software company must pay everyone in this economy
except the users, an open source economy must only pay the key players,
who make up perhaps 2-5% of the total. Further, the key players will
work for significantly less than the market rate, since they also derive
a real benefit from working on successful projects, which I call the
open source "payload".  The most important part of programmer's CV of
the future is the section titled "Open Source Projects".  This is the
payload.  It translates directly into dollars, proportional to the
impact and importance of the open source projects involved.

When compensation plus payload does not cover the cost of working on
a project (in terms of loss of compensation for alternative work), the
key player will suffer "burnout" after 12-18 months, more or less
depending on the person's tenacity.

Key Requirements
----------------

We can summarise the above discussion into a set of key requirements
for a successful open source project:

1. Quality at all levels.  The product must look and feel like a
   perfect machine: our target users identify with technology, not
   cosmetics.

2. An arena for discussions, at least email lists, and probably also
   interactive forums.

3. A clean web site with downloadable presentations, press releases,
   documents, flyers, and other material.

4. A regular release schedule with raw, fresh, and well-cooked packages
   (I.e. satisfying pioneers, early adopters, and late adopters).

5. An extensible software framework which provides players with a
   way to write addons of all types without wasting the time of the
   key players.

6. A forum or distribution channel for players to exchange and discuss
   their contributions.

7. A project identity and financial structure that attracts elite
   players and protects them from burn-out.

8. A clear financial rationale for the project that attracts patrons
   and ensures they get value for money.

9. Some arbitrary and controversial technical and/or licensing choices
   that keep the trolls happy and ensure the project gets discussed
   often on popular forums like Slashdot.

Insofar as we can "market" an open source project like OpenAMQ into
success, the categories I've defined are the market segments that need
to be addressed.  For instance, a project's web site should viewed from
the perspective of each of these roles and the question asked, "does
this make sense to me?"

Open Source Licenses
--------------------

There are numerous open source licenses, but modern projects tend to
use one of two main alternatives.  On the one hand there is the BSD
model, also used by Apache, which says "this code is free to use and
share but you must respect our copyright notices".  On the other hand
there is the GPL model, the basis of Linux, which says "this code is
free to use and share, and any modifications you distribute as binary
must also be shared as source."

The two approaches are strongly influenced by philosophies. The BSDL
originates from an academic desire to spread knowledge widely. The GPL
originates from the viewpoint that software-as-property is somehow evil.
It even promotes the notion of "copyleft" as an alternative to copyright,
though the license is only enforceable through copyright law.

Many academics and most commercial interests dislike the GPL because
it "infects" projects.  Even iMatix, who distribute their own projects
as free software under the GPL, prefer to work with BSDL libraries.
Why?  Because we can safely provide these to our commercial customers.

From the viewpoint of the success of open source projects, there is
contradictory evidence.  On the one hand, BSDL projects like Apache
have held a market lead against GPL alternatives.  On the other hand,
Linux has beaten the originally superior OpenBSD and FreeBSD systems
into obscurity.

There is much debate about the fine points of these two licenses, but
the truth appears to be that the BSDL suits better-funded, top-down
organisations while the GPL suits smaller, more distributed projects.
The successful GPL projects consist of many smaller pieces, each with
a few authors.  The successful BSD projects tend to be monolithic,
with larger teams.

The choice of license is probably both cause and effect.

For AMQ, we'd prefer to use the GPL as it fits our view of open source
as an economy.  The argument is that the GPL, though harder to "sell"
to our users, would create a more viable long-term economy around the
AMQ technologies.  However, we'd recommend using the BSDL (rather, the
Apache License) for practical reasons: it's what our target users will
want.

The Version 2 Syndrome
======================

A project like AMQ solves a problem that is very well defined and for
which there is a huge market. In a large global enterprise, there are
dozens, perhaps hundreds of potential applications where commercial or
ad-hoc middleware can be placed aside in favour of a simpler standard
solution.

The user community is sophisticated, having worked with middleware of
all flavours, and able to rapidly define the most ambitious goals in
terms of performance, stability, and functionality.

On the one hand this maturity is essential if we are to avoid making too
many mistakes while discovering the ideal solutions to the many problems
we have to solve.

On the other hand, this maturity of vision can become a danger to the
banality realities of building the project.  Too many features, added
too soon, turn the best source code into mush.

We describe our process for filtering functionality while keeping the
door open to future extensions.

Packing Light
-------------

The first rule we apply to any given functionality is: do we need it
now?  There are several criteria for this:

- Do our first target applications need it?
- Does it add essential credibility to the AMQ project?
- Do we know how to make it?
- Can we make it reasonably quickly and cheaply?

If the answer is 'yes' to most or all of these questions, we implement
the functionality. If 'no', we put it aside.

Packing light means making an unencumbered design. Every unused or idle
element of a design adds weight and cost. Knowing what not to do (yet)
is as important as knowing what to do.

Extensibility, Not Functionality
--------------------------------

The key to being able to say "we will do it later" is that the work will
be as easy and fast to do (possibly more so) in the future than now.

We aim to keep all structures general so that they can be extended and
added to easily. For example, we know that the AMQP specifications are
not complete, that it is missing large and (in some scenarios) vital
chunks, but we also have a good idea of where those chunks will go and
we do what we can to minimize the effect those future changes will have
on the design.

Change Management
-----------------

We treat change as an essential part of the design process. That is,
change in requirements, in design decisions, in the code, everywhere.
Every iteration of the software defines the design of the next.

This is possible because we rely heavily on code generation to leverage
our programming. It is simply a matter of inertia: fewer lines of code
to refactor means less work and fewer mistakes.

What Ships in Version 1.0?
--------------------------

The main functionality planned for version 1.0 of OpenAMQ is:

- queues and topics
- persistent and non-persistent messages
- routing by queue name, topic hierarchy, message header fields
- transaction management
- various types of message: simple, multi-part, streaming
- virtual hosts
- client APIs for C, C++, Java, COM, Perl
- project support structures: web site et al.
- SASL security
- access-control lists

Functionality that will probably not be included in version 1.0:

- XA transactions
- JMS selectors

And functionality that we still have to look at in more detail:

- system queues for remote administration
- web-based administration interface
- clustering and replication
- dynamic cluster organisation facilities
- server-side applications
- server plugins and filters

The Toolset
***********

In which we identify and name the giants upon who's shoulders we are
standing.

[openamq_tools.png]

Standard Libraries
==================

Apache Portable Runtime
-----------------------

APR provides a fairly rich set of functions for encapsulating
non-portable system functionality such as socket access, threading,
and so on.  We use APR moderately, mainly in the SMT framework.

APR is solid and clearly designed to support a communications
project such as OpenAMQ.  It is immature in several areas: weak
documentation, incomplete APIs, and some portability issues, but
overall we feel it's worth using.

Berkeley Database
-----------------

BDB is a mature ISAM system.  Our experience with it is somewhat
contradictory.  On the one hand, the product is well documented, widely
used in other projects, and very stable in operation.  On the other
hand, it is literally painful to program.  If you use the wrong sequence
of calls, it will simply abort, without any explanation.  Writing BDB
code is often a matter of trial and error.  All our calls to BDB are
in generated classes, so the pain of writing BDB code is one-time only.

We use BDB for message persistence, and for object persistence.

We are not entirely satisfied with BDB's performance: in order to get
a stable application, transactions must be used for all operations
(or we get those famous aborts).  Thus even database reads are
transactional, and the transaction logs tend to grow.  We will probably
write our own persistence layer at some stage.

Hazel's Perl Compatible Regular Expressions
-------------------------------------------

The PCRE library is a small and useful library that we use for parsing
and matching.  For instance in OpenAMQ this library does the parsing
and matching of topic names.

iMatix Standard Function Library
--------------------------------

SFL provides a similar library to APR.  It is more mature, and ported
to many platforms.  SFL is considered "legacy", in the sense that we
are not adding new functionality to it.

iMatix Portable Runtime
-----------------------

iPR is our modern replacement for those functions in SFL that we want
to use, and which are not provided by APR.  iPR is written using the
iCL framework (see below).

Languages
=========

ANSI C
------

We use ANSI 1989 C with a small set of necessary extensions that are
portable to our target systems (inlined functions, 64 bit integers).

iMatix Generator Scripting Language
-----------------------------------

We use the GSL code generator construction language to build the
many code generators that we use.  In most cases we actually generate
the code generators using the XNF framework (see below).

Perl
----

We use Perl in some parts of the process where GSL is not flexible
enough, mainly for document preparation.  Perl is widely available
and very useful, but tends to produce unmaintainable code, so we
do not rely on it very heavily.

Code Generation Frameworks
==========================

iMatix Class Library
--------------------

iCL is a software development methodology and toolkit aimed at constructing
very large and very high-quality applications in ANSI C.  We use C in
infrastructure projects because it is portable, fast and operationally stable.
However, C lacks modern facilities such as:

1. inheritance (where functionality can be added by extending and building on
   existing components)
2. templating (where variations on a standard model can be produced cheaply)
3. API standardization (where the structure of APIs is enforced by the
   language).
4. literate coding (where documentation can be written together with the code)
5. logical modelling (where we define abstract models such as finite state
   machines directly in the code)

These can be done manually, and usually are, but that is expensive and
demanding.

These facilities are helpful because they allow us to work faster and with
better results.  We can make larger and more ambitious designs with less risk
of losing control over them. iCL adds these facilities to C by wrapping it
into a higher level class library (1 - 3) which is self-descriptive (4),
simple, extensible and language independent. iCL adds a stage to the deployment
process, but unlike interpreted paradigms, portability and efficiency are
guaranteed as an atomic quality that follows as a natural consequence of the
target language, ANSI C. Our solution aims to leverage skills which are
normally part of the essential training of any IT professional (C, XML).

We write our programs as iCL classes, using a simple XML language. The XML
language (called "iCL") is designed to be easy to read and write by hand - no
special editors are needed. An iCL class consists mainly of a set of
properties and a set of methods. The properties define an object's state. The
methods define an object's functionality.

iCL classes compile into C code, which we then compile and link as usual.
In a best-case scenario, we can see up to a 10-to-1 ratio between the final
C code and the hand-written iCL classes, but coding effort compression is
typically non-negligible. The generated C code is perhaps 20-30% larger than a
comparable hand-written application, but we typically get less complex and
highly optimized code.

iCL does not attempt to create a full OO model. It aims to remove much of the
administrative burden from writing large-scale C applications, to produce
high-quality code (5), and to ensure that certain problems - such as memory
management - can be totally abstracted and thus solved "correctly" once and for
all.

iMatix Simple Multithreading Kernel
-----------------------------------

SMT/4 is the latest version of this kernel, which has driven our servers for
about a decade.  SMT/4 is built as an iCL application with a custom code
generator.  It provides:

- A finite-state model for writing "agents", which implement protocol
  handlers and other FSM-defined components.
- Functions for starting and stopping threads of control in an agent.
- Functions for communicating between threads, and between non-SMT code
  and SMT threads.
- Asynchronous socket i/o functions.
- Private context areas for each thread.
- Standard agents for logging, timer alarms, error handling, etc.
- The ability to package arbitrary agents together into applications.
- Overall management functions for starting and stopping SMT applications.

The OpenAMQ server, and the kernel clients, are written as SMT agents.
SMT/4 is quite a radical improvement over SMT/3, which used the Libero
code generation tool.  SMT/4 is full XML, and generates extremely flat
and fast finite-state machines (avoiding loops for most cases).  An SMT/4
application runs about twice as fast as an SMT/3 application.

iMatix XML Normal Form
----------------------

The iMatix team has been making XML-driven code generators for about
a decade, and more exotic code generators since 1985 or so.  In that
time, we've written several dozen major code generators and extracted
some basic principles:

- XML is without doubt the best language for abstract models, the
  input for code generation.

- Each XML file should represent a single "program", being a natural
  unit of work in whatever XML modelling language we are inventing.
  Trying to put multiple programs (state machines, classes, agents,
  whatever) into one XML file is counter-productive. Naturally one
  XML program can produce an arbitrary number of output files.

- The XML syntax should use attributes for item properties, items
  for structure, and item body content for code.  Using items for
  everything is verbose and confusing.

- We do not need to use schemas, stylesheets, paths, namespaces, or
  any of the more sophisticated XML paraphanalia.  We want simple XML
  that is easy to read and edit.  We do not want to have to use
  complex tools to read and edit our XML programs - just any text
  editor.

- The easiest way of mixing implementation code bodies and models is
  to write the code bodies in the XML, as item body content.  It
  helps if you use a tweaked XML parser that allows - for example -
  < and > inside an item body without complaining.

- The XML language should use inheritence to achieve abstraction.
  For example, in an finite-state model, states should be able to
  inherit events and their action lists from other 'abstract' states.
  Since XML is a hierarchical language, inheritence is a natural way
  of eliminating reduncancy in an XML program (something you might
  do in other languages using functions, classes, etc.)

- Doing all the above cleanly is sufficiently hard work that it's
  worthwhile generating the code generator from an abstract grammar.
  Using an abstract grammar makes it very cheap to extend and change
  the XML language so that it becomes suitably powerful.

XNF is thus a grammar tool and a code generator for building code
generators.  XNF is the meta grammar for iCL, SMT, boom, and XNF
itself.

This is a summary syntax for XNF:

    <xnf name version [before] [after] [abstract] [script] [copyright]
       [role]>
       <option name value/>
       <inherit name>
          <option .../>
       </inherit>
       <include filename/>
       <produce filename type/>
       <entity name [abstract] [template] [tag] [cdata] [key] [unique]
            [inherit] [sequence] [disconnect] [export]>
          <option .../>
          <inherit .../>
          <allow entity [occurs] [inherit] [sequence] [export]/>
          <rule [phase] [when]/>
          <attr name [required] [default] [inherit] [phase]>
             <restrict value/>
          </attr>
          <link from [entity] [field] [required] [disconnect]>
             <rule [phase] [when]/>
          </link>
       </entity>
       <errorhandler/>
       <rule [phase] [when]/>
    </xnf>

The only problem we find with XNF is that it is a meta tool and thus
difficult for some people to understand.  As a tool for generating code
generators it is very powerful and it abstracts concepts such as
inheritence that are very difficult to do well by hand.

Ad-Hoc Frameworks
-----------------

OpenAMQ has a number of ad-hoc code generation frameworks that are not
large enough to be worth defining with XNF:

- The AMQP frames generators, in versions that produce C, Java, and Perl
  code respectively.

- The openamq.org web site generator.

Documentation
=============

iMatix Gurudoc
--------------

iMatix gurudoc is a refinement of the htmlpp tool we used for our
websites for many years.

Gurudoc works by recognising layout in a simple text file, and converting
this to an internal XML language - GDL.  A set of code generators then
turn GDL into lots of different output formats.  Several varieties of
HTML (with frames, without frames), LaTeX (allowing PDF generation),
simple text, OpenOffice.org, RTF, etc.

Gurudoc keeps a balance between features and complexity, to give you
something useful without becoming too formal. Basically, gurudoc relies
on layout rules that also help to make the text readable in any case.
For example, blank lines and indentation are significant in most places.
One consequence of this is that the plain text file is very readable
even before it is converted to any target.

This document - like all the OpenAMQ documentation - is written as a
gurudoc text file.

LaTeX
-----

LaTeX is used to produce PDFs.  It's a huge system and does not build
on all our workstations.  But it produces very elegant PDFs.

AT&T Graphviz
-------------

Graphviz turns simple diagraphs into elegant images.  We use Graphviz
to produce the state and class diagrams used in this document.  Graphviz
is integrated into the gurudoc toolchain.

Wiki
----

The openamq.org web site provides a wiki whiteboard for developers.  We
use the Oddmuse wiki which is a simple and functional implementation.
We have modified the code to support gurudoc markup for wiki pages.

Project Management
==================

iMatix Boom
-----------

Boom is a portable command-line toolkit that automates the build process
for software projects. In simple terms, boom takes a project description
and turns this into various platform-dependent scripts and makefiles
that do the hard work of turning source code into executable files.

The short answer to the standard question "why use boom instead of make
or autoconf" is that make files are not portable, autoconf is complex,
and the build process requires more than these tools provide.

The longer answer is that boom projects are particularly cheap to make
maintain since files' properties are abstracted (using inheritence, as
usual) and relationships between files are extracted automatically.
Further, boom produces packages (source & binary) at no extra cost.

Boom produces make and configure scripts to give people a familiar
user interface.  Here is a typical project definition (for the
OpenAMQ documentation project, which includes this document):

    <?xml?>
    <pdl name = "OpenAMQ Documentation" version = "0.8c3">
    <include filename = "prelude.pdl" />
    <file name = "concepts.txt"          class = "gurudoc text" />
    <file name = "gdstyle.css"           class = "web resource" />
    <file name = "mainlogo.jpg"          class = "web resource" />
    <file name = "amq_server_agent.dot"  class = "digraph" />
    <file name = "amq_sclient_agent.dot" class = "digraph" />
    <file name = "amq_aclient_agent.dot" class = "digraph" />
    <file name = "server_classes.dot"    class = "digraph" />
    <class name = "digraph" inherit = "private resource">
        <derive extension = ".png"  class = "generated" />
        <generate target = "unix">
            <execute command = "builddot" />
        </generate>
    </class>
    </pdl>

Here is an edited fragment of the generated code (this implements the
'distsrc' command that builds a source package):

    rm -f _package.lst
    echo concepts.txt>>_package.lst
    echo gdstyle.css>>_package.lst
    echo mainlogo.jpg>>_package.lst
    echo amq_server_agent.dot>>_package.lst
    echo amq_sclient_agent.dot>>_package.lst
    echo amq_aclient_agent.dot>>_package.lst
    echo server_classes.dot>>_package.lst
    echo prelude.pdl>>_package.lst
    echo license.gpl>>_package.lst
    echo project.pdl>>_package.lst
    echo readme.txt>>_package.lst
    for file in `echo concepts*.html`; do
        echo $file>>_package.lst
    done
    echo amq_server_agent.png>>_package.lst
    echo amq_sclient_agent.png>>_package.lst
    echo amq_aclient_agent.png>>_package.lst
    echo server_classes.png>>_package.lst
    echo stamp_generate>>_package.lst
    echo configure>>_package.lst
    echo boomconf>>_package.lst
    echo Makefile_dev.unix>>_package.lst
    echo Makefile_src.unix>>_package.lst
    echo boomake>>_package.lst
    echo configure.bat>>_package.lst
    echo boomconf.bat>>_package.lst
    echo Makefile_dev.win32>>_package.lst
    echo Makefile_src.win32>>_package.lst
    echo boomake.bat>>_package.lst
    echo "Building OpenAMQ_Documentation-0.8c3-src.tar.gz..."
    zip  -rq _package.zip -@<_package.lst
    unzip -q _package.zip -d OpenAMQ_Documentation-0.8c3
    rm -f OpenAMQ_Documentation-0.8c3-src.tar.gz
    tar -czf  OpenAMQ_Documentation-0.8c3-src.tar.gz OpenAMQ_Documentation-0.8c3
    rm -f OpenAMQ_Documentation-0.8c3-src.zip
    echo "Building OpenAMQ_Documentation-0.8c3-src.zip..."
    zip -lrmq OpenAMQ_Documentation-0.8c3-src.zip OpenAMQ_Documentation-0.8c3
    rm _package.zip
    rm _package.lst

In typical projects boom produces about 100 lines of build code for one
line of project definition.  That is good leverage.

The AMQ Protocol
****************

This section is an extract from AMQ RFC 006, which defines the AMQ
Protocol.  [Note: this RFC is undergoing modifications.]

Overview
========

Purpose and Goals
-----------------

AMQP is intended to be a standardised general-use message-oriented
middleware wire-level protocol.  Such a thing does not yet exist, even
with fewer buzzwords.

A "wire-level protocol" can be a simple as a "this is how we define
packets on the wire".  AMQP is more ambitious than that.  It tries
to provide formal answers to a series of questions that we must
answer in order to implement useful messaging between protocols.

We want to be able to:

- Construct logical "messages" out of data of any type and size, and
  move these message efficiently across a network of clients and
  servers.

- Provide queuing and routing semantics for messages so that the
  behaviour of the server is unambiguously defined by the protocol.

- Define service levels semantics so client applications can explicitly
  choose between different levels of speed and reliability.

- Create a fully-asynchronous network so that messages can be queued
  when clients are disconnected, and forwarded when they are connected.

- Allow interoperation and bridging with other middleware systems.

- Allow implementation in any language, on any kind of hardware.

- Avoid license and patent concerns that might hinder adoption of the
  protocol as a standard.

- Create an architecture that is easy to maintain and extend over time.

- Allow the creation of an abstract network where services, and their
  data, can move around the network opaquely to the clients.

Negotiating a Connection
------------------------

Goals and Principles
....................

Negotiation means that one party in a discussion declares an intention
or capability and the other party either acknowledges it, modifies it,
or rejects it.  In AMQP, we negotiate a number of specific aspects of
the protocol:

1. The actual protocol and version.
2. Encryption arguments and the authentication of both parties.
3. Operational constraints.

Protocol and Version
....................

AMQP can co-exist with other (still to be defined) protocols on the
same socket.  These protocols would have to respect the AMQP protocol
negotiation model.

Protocol negotiation works as follows:

1. The client opens a new socket connection and sends a protocol ID and
   protocol version (each a double-octet value).
2. The server accepts the protocol by sending a valid response according
   to the protocol in question, or rejects the protocol by closing the
   connection.

The protocol negotiation model is compatible with existing protocols
such as HTTP that initiate a connection with an constant text string.

Protocol negotiation gives us the freedom to run multiple versions of
the same protocol, and multiple protocols, on a single socket, given
a server capable of doing this.

Encryption and Authentication
.............................

AMQP uses the SASL architecture for security.  SASL encapsulates TLS,
GSSAPI, Kerberos, and other encryption and authentication technologies.

Security is negotiated between server and client as follows:

1. The server sends a challenge to the client which lists the security
   mechanisms that the server supports.
2. The client selects a suitable security mechanism and responds to the
   server with relevant information for that security mechanism.
3. The server can send another challenge, and the client another
   response, until the SASL layer has received enough information.
4. The server can now use the selected security mechanism and
   authenticated client identity to perform access controls on its
   data and services.

The "relevant information" is an opaque binary blob that is passed
between the SASL layers embedded in the client and in the server.

SASL gives us the freedom to replace the security libraries with
better (more secure or faster) technologies at a later date without
modifying the protocol, the client, or the server implementations.

Client and Server Limits
........................

The protocol defines limits to ensure operational stability.  So, the
maximum size of a frame (explained later) is agreed in advance.  This
avoids deadlocks where one party sends data that is too large for the
other to handle.

Limits are negotiated as follows:

1. The server tells the client what limits it proposes.
2. The client can respond to lower the limits for its connection.

This gives us the flexibility of increasing limits such as buffer
sizes for better performance if both parties can handle it.

Command Framing
---------------

Goals and Principles
....................

There are several ways to define how commands start and stop on
connections:

- Sending a single command per connection.
- Adding command delimiters to the stream.
- Counting the size of commands and sending the size in front
  of each command.

AMQP uses the last technique.  Each command is formatted as a



Data Types
..........
bit	A single-bit value.  Bit values are accumulated into whole octets.
octet	An unsigned 8-bit integer.
short integer	An unsigned 16-bit integer held in network order.
long integer	An unsigned 32-bit integer held in network order.
short string	A string of 0 to 255 octets holding UTF-8 data. A short string is represented as a single octet followed by between 0 and 255 octets of data.  There is no trailing null character.  Short strings can contain any data including binary zero octets.
long string	A string of 0 to 216-1 octets holding UTF-8 data.  A long string is represented as a short integer followed by 0 or more octets of data.  There is no trailing null character.    Long strings can contain any data including binary zero octets.
blob	A binary object of up to 232-1 octets of data.  A blob is represented as a long integer specifying the blob length. Depending on the protocol implementation the blob contents may follow the frame, or may be provide by other means (such as through shared memory).

Code Generation
...............


Connection Multiplexing
-----------------------

Goals and Principles
....................

AMQP uses the concept of "channel" to carry multiple virtual connections
across a single socket. Channels correspond to threads in the client
applications.

Large messages are broken into "fragments" so that channels get fair use
of the socket connection.

AMQP is based on standard TCP/IP and does not implement any traffic
control mechanisms.

Connection States
.................

The client connects to a well-known or pre-agreed port and sends an
initial sequence that identifies the protocol it wishes to use. The
server replies with an authentication challenge. The client responds,
and the two parties then negotiate protocol options (such as maximum
frame size).

At this stage the client can open one or more channels, use these to
send commands to the server and receive commands back, and close
channels.

The "channel" concept is designed to support a single application thread
that can work with many different queues and topics ("destinations"),
but does so in a serial manner.

A good metaphor for a "channel" is a bidirectional data stream.
Everything that happens on a channel is serial, with asynchronous
activity in both directions. Parallelism means using multiple channels
at once. A single-threaded application would use a single channel.


Channel States
..............


Pipelining
----------

Goals and Principles
....................

Clients and servers exchange commands and messages asynchronously. There
is no polling.

Clients can batch commands, both implicitly by sending ahead of an
expected response, and explicitly by telling the server to not respond
in case of success.

Command Batching
................

Command Confirmations
.....................


Error Handling
--------------

Goals and Principles
....................

The basic server response to any error is to respond with an reply code
and a 'close' command. For example, if the client tries to open a handle
to a non-existent destination, the server will respond with a close
command carrying the reply code '404'.

Depending on the severity of the error the server may close the handle,
the channel, or the connection.

Response Code Families
......................
We use a standard 3-digit reply code that is compatible with BEEP.  The reply code is constructed as follows:
First digit ? completion ? reports whether the request succeeded or not:
1 = ready to be performed, pending some confirmation.
2 = successful.
3 = ready to be performed, pending more information.
4 = failed, but may succeed later.
5 = failed, requires intervention.
Second digit ? category ? provides more information on failures:
0 = error in syntax.
1 = the reply provides general information.
2 = problem with session or connection.
3 = problem with security.
4 = application-specific.
Third digit ? instance ? distinguishes different situations with the same completion/category.

Message Definition
------------------

Goals and Principles
....................

Message Properties
..................

MIME Types
..........

Content-Type	The MIME content type of the message body.  The default value is ?application/octet-stream?.
Transfer-Encoding	The transfer encoding for the message body.  The default value is ?binary?.

Content-Identifier	The business identifier of the message body, for instance a filename or database key.  The Content-Identifier must have a valid meaning to all parties processing the message, within the context of the current destination.

Message Body
............

Multi-Part Messages
...................

For example a
binary data file could be sent together with an XML description, as two
parts of a single message. The XML description might be used for
routing, without the need to inspect or unpack the binary data, and AMQP
will always deliver the multiple parts as as single message.

Empty Messages
..............

Message Priorities
..................

Queueing and Routing Models
---------------------------

Goals and Principles
....................

Service Types
.............

To publish data the client opens a "handle", then sends messages to
destinations using that handle. Handles are local to a specific channel.
When a client publishes to several handles within a channel, it does
this one after the other.

Large messages are split into fragments. This gives different channels -
but not handles - the ability to share a single socket connection.

There is no practical limit to the size of a message, and AMQP allows
streamed data - I.E. messages that never end.

Handles exist mainly to allow access control on part of a destination
hierarchy. If such access controls are not needed, all work on a channel
can be done using a single handle.

Topic Hierarchies
.................

Content-Based Routing
.....................

Programmable Routing
....................

Message Browsing
................

Destinations
------------

Goals and Principles
....................

Queues and Topics
.................

Consumers
.........

Transactions
............

Clients can send command without waiting for a server response. In most
cases the client can actively solicit a response or tell the server to
respond only on failure.

As a natural wrapping of command batches, we support transactional
processing. Typically the client will use the 'commit' command at the
end of a batch of messages and acknowledgements.

Transactions are applied to channels.

Message Acknowledgements
........................

To consume data, the client opens a handle, then asks to consume
messages from destinations using that handle.

The server sends messages using a dispatching model that depends on the
type of destination. For queues, messages are distributed between the
consumers. For topics, messages are copied to each of the consumers.

We control the number of unacknowledged messages sent to any single
client using windowing.



Dynamic Destinations
....................

Virtual Hosts
-------------

Goals and Principles
....................

A single server instance can support multiple "virtual hosts". A virtual
host has its own set of destinations and access controls. The client
application chooses the virtual host by specifying a path after
connecting and authenticating itself.

Security
--------

Goals and Principles
....................

Buffer Overflows
................

All data is length-specified so that applications can allocate memory in
advance and avoid deadlocks. Length-specified strings protect against
buffer-overflow attacks.

Denial of Service Attacks
.........................

AMQP handles errors by returning a response code and then closing the
channel or connection. This avoids ambiguous states after errors.

Performance
-----------

Goals and Principles
....................

Zero Copy
.........

The fastest network performance comes from using 'zero copy' techniques
such as RDMA where the network card will transfer data without any
copying or remapping by the OS. AMQP supports zero copy techniques for
message data (not for command frames).

Heartbeating
............

Although TCP/IP guarantees that data is not dropped or corrupted it can
be slow to detect that a peer process has gone "offline". AMQP provides
a heartbeat mechanism that can be tuned to allow rapid fail-over.







