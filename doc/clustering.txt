gdl
    title     = AMQ Clustering
    subtitle  = Providing Reliability and Scalability
    product   = OpenAMQ
    author    = iMatix Corporation <amq@imatix.com>
    date      = 2005/10/21
    copyright = Copyright (c) 2004-2005 JPMorgan
    version   = 1.2a1
end gdl

General Discussion
******************

What is "Clustering"?
=====================

We use the term "cluster" to mean a set of servers that are tied
together in such a way as to create a single virtual server:

           +------------------+------------------+
           |                  |                  |
    +------+-----+     +------+-----+     +------+-----+
    |            |     |            |     |            |
    |   Server   |     |   Server   |     |   Server   |
    |            |     |            |     |            |
    +------+-----+     +------+-----+     +------+-----+
           |                  |                  |
           +------------------+------------------+
                              | Cluster
                              |
    --------------------------+-------------------------
                              |
                       +------+------+
                       |             |
                       | Application |
                       |             |
                       +-------------+

Note that the servers may be physically distant.  We do not use the
term to describe sets of interconnected servers that serve different
sets of applications, e.g.:

        +---+                      +---+
      +-+   +-+                  +-+   +-+
      |       |      Bridge      |       |
      |       | ---------------- |       |
      +-+   +-+                  +-+   +-+
        +-+-+                      +-+-+
          |                          |
          |                          |
    +-----+-----+              +-----+-----+
    |           |              |           |
    |Application|              |Application|
    |           |              |           |
    +-----------+              +-----------+
      New York                     Tokyo

The correct term for this is "bridging", something that is done by
specialised applications.  See the document entitled "AMQ Bridging".

Why Cluster?
============

The main reasons for clustering are:

1. Reliability: using redundant servers so that if one fails, another
   can take its place.  Reliability is principally for point-to-point
   messages, the classic "queue service" scenario.

2. Scalability: using multiple servers so that work can be distributed
   over more boxes and/or networks.  Scalability is principally for
   transient publish/subscribe messages, the classic "topic service"
   scenario.

Since AMQ allows applications to mix the classic concepts of queue and
topic into arbitrary messaging models, AMQ clustering must support both
reliability and scalability, though these are somewhat different
problems.

Features of AMQ Clustering
==========================

We have some specific design goals for AMQ clustering:

1. Simple to configure, administrater, and use in applications.

2. Simplicity of implementation, except where the system becomes more
   complex to use.

3. Ability to scale to any size.

4. Ability to use arbitrary storage systems (SAN, RAID, IDE).

5. A single solution that provides both scalability and reliability,
   albeit targetted towards specific application scenarios.

Terminology
===========

We use the term "persistent" to mean data that is saved on disk, and
survives server restarts. This is contrasted with "transient", which
means data held only in memory, and lost if the server restarts. We use
the term "reliable" to mean persistent data that is mirrored in some way
to make it robust against disk failures.

Levels of Reliability
=====================

We can define four levels of message reliability, each providing a
different cost/reliability trade-off:

 - Fully transient: the message is held only in one memory and is
   lost if that memory is reset.

 - Reliable transient: the message is replicated to a second memory
   and is lost only if both memories are reset.

 - Persistent: the message is saved to a single disk system and is
   lost if that disk system is damaged.

 - Reliable persistent: the message is saved to two distinct disk
   systems and is lost only if both disk systems are damaged.

Transactions vs. Messages
=========================

Although AMQ is a message-oriented middleware system, it is useful to
consider reliability in terms of "transactions". A transaction consists
of a set of actions that imply change to the server state, and
specifically, the set of messages held by a queue:

 - The simplest transactional model wraps every method in a transaction.
   We call this an "automatic transaction".

 - The classic transaction model wraps a set of methods in a transaction.

 - The distributed transaction model coordinates transactions across a
   set of servers using a distributed transaction coordinator.  This is
   more complex than we want to implement at present.

Transactions can cover any mix of persistent, or transient messages, and
durable or temporary queues.

We do not make any a-priori distinction between persistent and transient
messages, except that they are stored on more or less reliable media.
We might have several types of persistent messages, for instance.

General Solution for Reliability
================================

We consider the problem of storing persistent transactions in such a
way that a server or disk system failure does not cause loss of data.
This is the classic "reliable point-to-point messaging" scenario.

The cluster consists of two servers, one acting as "primary" and one as
secondary. In normal operation, all clients connect to the primary
server, as shown by this diagram:

        +-----------+        +-----------+
        |           |        |           |
        |  Primary  +--------+  Backup   |
        |  Server   +--------+  Server   |
        |           |        |           |
        +----/+\----+        +-----------+
           // | \\
          /   |   \\
         /    |     \
       //     |      \\
     //-\    /+-\    /-\\
    |    |  |    |  |    |
    |    |  |    |  |    |
     \--/    \--/    \--/

      Client Applications

Each server maintains its own storage, and the primary server replicates
transactions to the secondary server as follows:

        -----                -----
      //     \\            //     \\
     | Disk 1  |          | Disk 2  |
      \\     //            \\     //
        --+--                --+--
          | ||||||             | ||||||
          |  B                 |  D
    +-----+-----+        +-----+-----+
    |           |  C     |           |
    |  Primary  +-||||||-+  Backup   |
    |  Server   +--------+  Server   |
    |           |     E  |           |
    +-----+-----+        +-----------+
          | ||||||
         F|  A
          |
         /+-\
        |    |
        |    |
         \--/
        Client

 - (A) The client prepares a transaction (publishes messages and
   acknowledges received messages) on the primary server.  The
   client then does a COMMIT.

 - (B) The primary server writes this transaction to disk.  It may
   or may not flush the disk, this is a matter of optimisation.

 - (C) The primary server passes the transaction to the backup
   server.

 - (D) The backup server writes this transaction to disk.  Again,
   it may or may not flush the disk depending on the degree of
   reliability wanted.

 - (E) The backup server confirms that the transaction has been
   recorded safely.

 - (F) The primary server confirms to the client application that
   the transacton has been completed.

If the primary server fails, the client can detect this and switch
to the backup server:

           -----                -----
         //     \\            //     \\
        | Disk 1  |          | Disk 2  |
         \\     //            \\     //
           --+--                --+--
             |                    |
          ---+---                 |
      / //-------\\ \       +-----+-----+
     | |           | |      |           |
    |  |  Primary  |  |     |  Backup   |
    |  |  Server   |  |     |  Server   |
     | |           | |      |           |
      \ \\\-----/// /       +-----------+
           -----            ----
                        ----
                    ----
                ----
            /--\
           |    |
           |    |
            \--/
           Client

There are some non-trivial details to solve, such as:

 - How does the secondary server know the primary server has
   crashed?  How can it differentiate this from - e.g. - a
   network failure?

 - How does the client know which server is the primary and
   which is the secondary?

 - What happens if the secondary server crashes?  Does this
   need special attention?

 - How does the primary server come back on-line?

 - Can we extend this solution to N servers, and does that help
   to provide a more general (and simpler) solution?

We will work through these in the detailed design section.

General Solution for Scalabilty
===============================

We consider the problem of handling very large numbers of clients (100k
or more) that consume data from a small number of high-volume
publishers. This is the classic "transient publish-subscribe scenario".

This scenario has several particular features:

 - It does not use persistent transactions. This means
   there is no requirement to replicate transactions.

 - It has a strong fan-out ratio from publishers to subscribers.
   This means the same message can be sent to very many end-points.

We in fact have two kinds of client application, publishers and
subscribers, and we can draw the cluster like this, showing a
set publisher and several sets of subscribers:

                       Publishers
                          ---
                        //   \\
                       |       |
                       |       |
                        \\   //
                          -+-
                           |
          +----------------+-----------------+
          |                |                 |
    +-----+-----+    +-----+-----+     +-----+-----+
    |           |    |           |     |           |
    |  Server   +----+  Server   +-----+  Server   |
    |           |    |           |     |           |
    +-----+-----+    +-----+-----+     +-----+-----+
          |                |                 |
          |                |                 |
        /-+-\            /-+-\             /-+-\
       |     |          |     |           |     |
       |     |          |     |           |     |
        \---/            \---/             \---/
     Subscribers      Subscribers       Subscribers

 1. Subscribers are distributed across the servers, so that each
    server has a segment of the subscriber population.

 2. Subscriptions (AMQ bindings and subscription queues) are held
    separately for each subscriber on 'their' server.

 3. Every publisher sends every message to every server.

It is clear that this model only works where we can exploit a strong
fan-out from publisher to subscriber.  If every published message goes
only to a few subscribers, this model will not provide any advantage.

Failover is relatively easy: all subscribers from the failing server
reconnect to another server, resubscribe, and start to collect their
messages.

In addition to the questions raised for the reliability design, we must
answer these questions for the scalability design:

 - How do subscribers decide which server to connect to?

 - Where does the 'fan-out publish' intelligence sit?

 - Where does the 'recreate subscriptions' intelligence sit?

 - How do we support (more or less) reliable durable subscriptions with
   persistent messages?

We will work through these questions in the detailed design section.

Design Methodology
==================

Our design methodology is the conventional one: start with the simplest
plausible model, and build up from there.  We will define a series of
"levels", each more complex.  Each level is fully implementable, and
will implement and test each level before attempting the next.

Level 0 Clustering
******************

Functional Goals
================

Level 0 clustering is our ground floor. This provides system failover
without any data reliability or state replication. 

We do not attempt to safeguard persistent messages, transactions,
durable resources, or connection state. All messages are "fully
transient" (i.e. held in a single memory only), and all queues and
bindings are temporary and created on-demand.

The main functionality of level 0 clustering is to redirect clients to
the "right" server and to allow graceful failover to a backup server.

We expect that some of the design decisions in the Level 0 clustering
proposal will be "wrong", but we feel it is more important to implement
a minimal working solution and learn from that than to attempt to design
the complete and perfect solution without intermediate stages.

Level 0 clustering is a problem is worth solving because:

 1. It is a real problem that we must solve for our first target
    applications.

 2. It is significantly simpler than the full clustering problem.

General Implementation
======================

Level 0 clustering has this general organisation:

 - The cluster consists of two servers: one is the "primary" server
   and the others is the "secondary" server.

 - All clients connect the primary server.

 - All queues are created and held on the primary server.

 - All clients publish messages to the primary server.

 - The primary and secondary servers are connected and monitor each
   other for failure.

If the primary server crashes, the fail-over process is as follows:

 - The secondary server takes over the role of primary server.

 - The clients of the old primary server reconnect to the new primary
   server.

 - The clients recreate all state (queues, consumers, etc.) on the new
   primary server.

 - Clients can start publishing again.

The recovery process is as follows:

 - The old primary server is restarted and checked, and now assumes the
   role of secondary server.

Server-side Functionality
=========================

The cluster looks like this:

    +-----------+        +-----------+
    |           |        |           |
    |  Primary  +--------+ Secondary |
    |           |        |           |
    +-----+-----+        +-----------+
          |
          |
        /-+-\
       /     \
      |Client |
       \     /
        \---/

We build a cluster failover model that:

 1. Does not require any external administration or manual control.

 2. Does not require any external tokens or shared resources.

 3. Is invisible to the client applications.

The servers are interconnected, so if the primary server crashes or
freezes, the secondary server can unambiguously detect this. However,
if the network connection between the two servers dies, this may give
a similar symptom, while in fact the primary server is still running.

The main difference between the two scenarios is this: if the primary
server really crashes, the cluster clients will start to reconnect at
the secondary server. Until this happens, even if the primary server
goes offline, the secondary server does not need to change its role.

The secondary server must rely on the clients to confirm that the
primary server has really gone away.  So, failover works as follows:

 1. The secondary server monitors the primary server, and if that
    server stops responding or disappers, the secondary server
    puts itself into "alert" mode.

 2. When a client connects to the secondary server, in alert mode,
    the secondary server redirects the client to the primary server.

 3. The client can force the connection, using the "insist" option
    on the new connection.  In this case, when in alert mode, the
    secondary server now knows that at least one client confirms
    that the primary server has gone.  It switches to the role of
    primary server and accepts the client connection.

We can solve the question of how to nominate a primary server at startup
using the same technique.

 - First, the cluster has a static configuration that is shared by
   all servers. By convention, when all servers start at the same time,
   the first server that is defined will take the role of primary server.

 - If the primary server has failed, and the cluster is restarted, the
   procedure will work following the above scenario for failover; the
   secondary server will take on the role of primary server when it gets
   a client that insists on connecting to it.

 - Lastly, so that the superceded primary server does not nominate
   itself as current primary, when that role has already been taken, we
   use some simple inter-server communcation: the primary server will
   open a port, and before taking on the role of primary server, a
   newly-starting server will first probe the other server(s) to
   see if there is already a primary server.

This lets us start the cluster in any order, and lets us switch an
old primary server back on after a failure (it will assume the role
of secondary server).

The design has one flaw that we can see: if there are intermittent
communication problems both between the servers, and between the
servers, and clients, we may get both servers acting as primary
server at some stage.  This would cause messages to get lost, with
producers and consumers unable to communicate.

To avoid this risk, the servers should continuously verify that
they are not usurping the role of primary server, by checking the
other server.  The "junior" server, detecting such a conflict, will
disconnect its clients, and become a secondary server.

Client-side Functionality
=========================

To work with this cluster design, the client application must be able
to:

 1. Reconnect to the cluster if it is disconnected for any reason.

 2. Recreate all transient resources (temporary queues, consumers, etc.)

 3. Resume work.

The client API (StdC or Java) must be able to:

 1. Connect to an arbitrary cluster server, by trying them all at random
    until one accepts the connection.

 2. Disconnect and reconnect to a different server, if the first choice
    of server requests this.  (We call this a "redirection").

 3. Reconnect to the first choice if the redirection fails, using the
    "insist" option.

 4. Detect a server failure and report this to the application (this is
    already a standard part of the API).

Implementation Details
======================

AMQ Protocol
------------

 - Addition of S:Connection.Redirect method.

 - Addition of insist option to S:Connection.Start method.
 
Client APIs
-----------

 - Accept multiple server names in connection string.

 - Connect to random server.

 - Handle S:Connection.Redirect method as defined above.

Applications
------------

 - Handle server disconnection by restarting connection logic from
   scratch.

OpenAMQ Server
--------------

 - Configuration file for cluster definition.
 
 - Server "active" / "passive" mode.

 - Implement Connection.Redirect for passive mode.

 - Cluster monitoring agent (asynchronous agent that monitors other
   servers).

Level N Clustering
******************

Extensions to Level 0. These are different issues that we want to
discuss and get authoratitive answers to whether we tackle them, and if
so, how. This list is not meant to be exhaustive.

Cluster Console
===============

Question:
    Can we provide a single view for operators of a cluster?
Answer:
    For general administration this is not a good idea. Each cluster
    server has its own set of queues and needs to be manageable by
    itself. For configuration this is a good idea.
Method:
    To create a single configuration file, we can either use shared
    storage (NFS) or pass configuration data between servers.
Pros:
    A single configuration for the cluster is highly desirable. E.g.
    security controls are set once, and apply everywhere.
Gotchas:
    Shared storage is simple but creates a dependency on some other
    server. Passing configuration data between servers is more complex,
    needing server-side intelligence, or a cluster-aware console.

Connection State Replication
============================

Problem:
    Can we make the cluster smart enough to hold all connection
    state so that a client application can failover without
    restarting?
Answer:
    Yes, so long as the cluster itself is reliable. If there is
    a problem between the cluster servers, connection state can't be
    replicated reliably.
Method:
    Primary server acts as client of secondary server, and passes
    all connection commands through. Secondary server thus holds same
    set of queues, consumers, channels as primary server, for given
    client connection. Both servers use same 'connection key'.  If primary
    server goes away, client reconnects to secondary server using
    connection key, and gets back its resources.
Gotchas:
    If primary and secondary server cannot communicate reliable,
    connection state will be wrong or out of date.  We could try to
    detect this and force a client disconnection if that happens.
    Then the application must be able to restart (Level 0 behaviour).
Pros:
    Much faster failover, handled at client API level, rather than
    application. Reconnection (and connection state recovery) is already
    defined in AMQP and supported by the StdC client.
Cons:
    Reconnection protocol may be complex to implement in non-StdC
    client APIs.

Transactional Memory
====================

Problem:
    How to treat memory and disk through a single transactional
    API that happens to have different implementations?
Answer:
    Not really a clustering problem but possibly a key solution.
Method:
    Define transaction-based API for writing messages to queues,
    and removing messages from queue.  Implement API using pure
    memory, for transient messages, and using arbitrary storage
    layers, for persistent messages.  Note that single transaction
    can cover multiple queues, so transactions should be set at
    virtual host level.
Pros:
    Abstracting persistence makes queue and cluster implementation
    much simpler.
Cons:
    May add unwanted overhead for non-transacted messages. If used
    systematically, memory implementation must be as rapid as current
    queue implementation (based on ordered memory lists).

Reliable Transient Messages
===========================

Problem:
    Can we copy messages to the backup server so that if the
    primary server fails, a reconnecting client will find queues
    that are populated with the messages?
Answer:
    Yes, as an extension of state replication.
Method:
    Primary server would manage the secondary queues by proxy,
    consuming messages and sending acknowledgements to the secondary
    server according to the client's work. Probably simplest
    implementation is as transaction replication (where transaction
    happens to use memory rather than disk as storage).
Reliability:
    If primary server fails, transient messages will not be lost.
Gotchas:
    Assumes reliable communications between servers. 

Reliable Persistent Messages
============================

Problem:
    To copy persistent messages across to backup server.
Method:
    As extension of reliable transient messages, using transactions,
    and using persistence to hold messages.
Pros:
    Enterprise-level clustering, this is what people really want for
    their business-critical data.
Gotchas:
    Needs message persistence, and transaction replication, but
    these are both solvable as independent problems, it seems.

Multiple Secondaries
====================

Problem:
    How do we support N servers rather than just two?
Method:
    Servers share common configuration file and agree on order of
    succession. Each server tracks current primary and applies Level
    0 algorithm in deciding to take over.  All servers monitor for
    possible conflicts, and junior server (defined as server with
    fewest clients?) steps back.
Pros:
    More servers = more reliability (if done correctly).
Cons:
    Servers need to be visible to client application, creating
    administration difficulties.

Topic Fanout
============

Problem:
    How can we segment clients across multiple servers so that we
    can use whole cluster actively, rather than just one server at
    a time?
Method:
    Consumers will attach to a single server, publishers will send
    messages to all servers. Relies on high-degree of fanout, with
    same message going to many consumers.
Pros:
    Scalable to high-volume pub-sub scenarios. Could be layered on
    level 0 with small changes.
Gotchas:
    How do we mix this with reliable messaging? Maybe, using virtual
    host as key. I.e. a virtual host implements a specific clustering
    model, and connections are to virtual hosts within the cluster.

Clustering Agent
================

Problem:
    Can we let trivial clients to work usefully with a cluster?
Answer:
    Yes, but it needs some assistance at the client side.
Method:
    Proxy "cluster agent" layer, run as process on client system,
    stopped and started by client API as needed. Cluster agent
    de-virtualises server address, using configured knowledge of
    cluster: turns single server address into cluster lookup. Cluster
    agent implements re-connection, redirection, etc.
Pros:
    Can be implemented cheaply using existing technology. Can work
    with any client technology. Hides cluster totally from client.
    Allows full virtualization, i.e. cluster address and structure can
    be completely hidden and updated dynamically. Creates a single point
    for adding extra client-side intelligence. Lets us build very large
    clusters with dumb clients.
Cons:
    Extra process on client server. Starts to look like p2p, may be
    confusing for some people.
Gotchas:
    None. This seems an elegant way to help unsophisticated applications
    get onto an AMQ cluster.  

Proposed Evolution
******************

We propose the following plan for implementing the different aspects
of clustering:

 - Level 1: topic fanout, cluster console, multiple secondaries.
   This addresses GTW needs.

 - Level 1b: transactional memory, connection state replication.

 - Level 2: reliable transient messages, reliable persistent messages,
   clustering agent.

Level 1 Clustering
==================

We do not add any message reliability, but we add scalability for
large-scale transient pub/sub, and ensure the cluster can be managed
using the AMQ Console. We generalise the cluster from two to N servers,
consisting of a primary and a secondary for shared queues, and a
set of segmented servers for topic pub/sub.

Level 1b Clustering
===================

We move the queues onto a transactional memory model, with both
transient (memory) and persistent (disk) implementations. We do not
attempt to replicate transactions, but we do replicate the basic
connection state to allow faster failover for scenarios where response
time is critical.

Level 2 Clustering
==================

We implement transaction replication, for transient and persistent
messages, and on temporary and durable queues.

