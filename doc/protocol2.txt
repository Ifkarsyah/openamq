General Architecture
********************

The AMQ Framework
=================

This section explains the server semantics that must be standardised
in order to guarantee interoperability between AMQ implementations.

Main Entities
-------------

This diagram shows the overall AMQ framework:

                                 Server
                      +----------------------------+
                      |       Virtual host         |
                      |   +-------------------+    |
                      |   |     Exchange      |    |
    +-------------+   |   |     +-------+     |    |
    |  Publisher  | ----------> |       |     |    |
    | application |   |   |     +---+---+     |    |
    +-------------+   |   |         |         |    |
                      |   |         |         |    |
                      |   |       Queue       |    |
    +-------------+   |   |     +-------+     |    |
    |  Consumer   | <---------- +-------+     |    |
    | application |   |   |     +-------+     |    |
    +-------------+   |   |     +-------+     |    |
                      |   +-------------------+    |
                      +----------------------------+

We can summarise what a middleware server is: it is a data server that
accepts messages and does two main things with them, it routes them to
different consumers depending on arbitrary criteria, and it buffers them
in memory or on disk when consumers are not able to accept them fast
enough.

In a pre-AMQ server these tasks are done by large monolithic engines
that implement specific types of routing and buffering. AMQ takes the
approach of smaller, modular pieces that can be combined in more diverse
and robust ways. It starts by dividing these tasks into two distinct
roles:

 - The exchange, which accepts messages from producers and routes them
   queues.

 - The server queue, which stores messages and forwards them to consumer
   applications.

There is a clear interface between exchange and server queue, called a
"binding", which we will come to later. The usefulness of the AMQ
framework comes from three main features:

 1. The ability to create arbitrary exchange and server queue types
    (some are defined in the standard, but others can be added as
    server extensions).

 2. The ability to wire exchanges and queues together to create any
    required message processing system.

 3. The ability to control this completely through the protocol.

What AMQ provides is a server with runtime-programmable semantics.

The Server Queue
................

A server queue stores messages in memory or on disk, and delivers these
in sequence to one or more consumer applications. Server queues are
message storage and distribution entities. Each server queue is entirely
independent and is a reasonably clever object.

A server queue has various properties: private or shared, durable or
temporary, client-named or server-named, etc. By selecting the desired
properties we can use a server queue to implement conventional
middleware entities such as:

- A standard "store and forward" queue, which holds messages and
  distributes these between consumers on a round-robin basis. Store and
  forward queues are typically durable and shared between multiple
  consumers.

- A temporary reply queue, which holds messages and forwards these to a
  single consumer. Reply queues are typically temporary, server-named,
  and private to one consumer.

- A "pub-sub" subscription queue, which holds messages collected from
  various "subscribed" sources, and forwards these to a single consumer.
  Subscription queues are typically temporary, server-named, and private
  to one consumer.

These categories are not formally defined in AMQ: they are examples of
how server queues can be used. It is trivial to create new entities such
as durable, shared subscription queues.

The Exchange
............

An exchange accepts messages from a producer application and routes
these to server queues according to pre-arranged criteria. These
criteria are called "bindings". Exchanges are matching and routing
engines. That is, they inspect messages and using their binding tables,
decide how to forward these messages to server queues or other
exchanges. Exchanges never store messages.

An exchange exists at two levels. First, there is the code itself. When
we discuss what an exchange can or cannot do, we speak of the code.
Second, there is the running instance. When we send a message to an
exchange, we send it to a running instance.

In some contexts this separation between the code and the instance is
obvious - for instance, the term "AMQ server" means both the static code
and the active running process. However, when speaking of an AMQ
exchange as an entity inside the AMQ server, the separation is less
clear. To clarify it, we define that:

 1. The algorithm for an exchange - its code - is the "exchange type".

 2. All exchanges must be started as instances before they can be used.

 3. All exchange instances are explicitly named.

We will take an example, an imaginary exchange type, "filter", capable
of recognizing illegal messages - e.g. too large - and rejecting these.
To use the filter exchange type, we create a new exchange instance,
named "my.filter". When applications wish to filter messages, they will
refer to "my.filter", not "filter".

For a number of reasons, it is useful to allow an unlimited number of
exchange instances.  In a typical server we would expect to see a
handful of instances, in very complex scenarios, somewhat more.

The Routing Key
...............

In the general case an exchange examines a message's properties, its
header fields, and its body content, and using this and possibly data
from other sources, decides how to route the message.

In the majority of simple cases the exchange examines a single key
field, which we call the "routing key". The routing key is a virtual
address that the exchange uses to decide how to route the message.

For point-to-point routing, the routing key is the name of a server
queue. For topic pub-sub routing, the routing key is the topic hierarchy
value. In more complex cases the routing key may be combined with
routing on message header fields and/or its content.

Analogy to Email
................

If we make an analogy with an email system we see that the AMQ concepts
are not radical:

 - an AMQ message is analogous to an email message.
 - a server queue is like a mailbox.
 - a consumer is like a mail client that fetches and deletes email.
 - a exchange is like a MTA (mail transfer agent) that inspects email
   and decides, on the basis of routing keys and tables, how to send the
   email to one or more mailboxes.
 - a routing key corresponds to an email To: address, without the
   server information (routing is entirely internal to an AMQ server).
 - each exchange instance is like a separate MTA process, handling some
   email subdomain, or particular type of email traffic.
 - a binding is like an entry in a MTA routing table.

The power of AMQ comes from our ability to create queues (mailboxes),
exchanges (MTA processes), and bindings (routing entries), at runtime,
and to chain these together in ways that go far beyond a simple mapping
from "to" address to mailbox name.

We should not take the email-AMQP analogy too far: there are fundamental
differences. The challenge in AMQP is to route and store messages within
a server. The challenge in email is to route messages between servers.
The addressing models are thus fundamentally different. Routing within a
server and between servers are distinct problems and have distinct
solutions, if only for banal reasons such as maintaining transparent
performance.

Message Flow
------------

This diagram shows the flow of messages through the AMQ server:


    +-------------+                    +-------+
    |  Publisher  | -----------------> |Message|
    | application |                    +---+---+
    +-------------+                        |
                                           |
                                      +---------+
                                      |Exchange |
                                      +----+----+
                                           |
                              +------------+------------+
                              |            |            |
                            Queue        Queue        Queue
    +-------------+       +-------+    +-------+    +-------+
    |  Consumer   |       +-------+    +-------+    +-------+
    | application | <---- |Message|    +-------+    +-------+
    +-------------+       +-------+    +-------+    +-------+

Message Lifecycle
.................

An AMQ message consists of a set of properties plus a content. A new
message is created by a producer application. The producer sends the
message to an exchange. The exchange (usually) routes the message to a
set of server queues. If the message is unroutable, the exchange may
drop it or bounce it back to the producer. The producer chooses how
unroutable messages are treated.

A single message can exist on many queues. The server can handle this in
different ways, by copying the message, by using reference counting,
etc. This does not affect interoperability. However, when a message is
routed to multiple queues, it is identical on each queue. There is no
unique identifier that distinguishes the various copies.

When a message arrives in a server queue, the queue tries immediately to
pass it to a consumer application. If this is not possible, the queue
stores the message (in memory or on disk as requested by the producer)
and waits for a consumer to be ready. If there are no consumers, the
queue may bounce the message back to the producer (again, if the
producer asked for this).

When the queue can deliver the message to a consumer, it removes the
message from its internal buffers. This can happen immediately, or after
the consumer has acknowledged that it has successfully processed the
message. The consumer chooses how and when messages are acknowledged.
The consumer can also reject a message (a negative acknowledgement).

Producer messages and consumer acknowledgements are grouped into
transactions. When an application plays both roles, which is often, it
does a mix of work: sending messages and sending acknowledgements, and
then committing or rolling back the transaction. Message deliveries from
the server to the consumer are not transacted.

What The Producer Sees
......................

By analogy with the email system, we can see that a producer does not
send messages directly to an server queue. Allowing this would break the
abstraction in the model. It would be like allowing email to bypass the
MTA's routing tables and arrive directly in a mailbox. This would make
it impossible to insert intermediate filtering and processing, spam
detection, for instance.

The AMQ framework uses the same principle as an email system: all messages
are sent to a single point, the exchange or MTA, which inspects the
messages based on rules and information that are hidden from the sender,
and routes them to drop-off points that are also hidden from the sender.

What The Consumer Sees
......................

Our analogy with email starts to lose focus when we look at consumers.
Email clients are passive - they can read their mailboxes, but they do
not have any influence on how these mailboxes are filled. A consumer can
also be passive, just like email clients. That is, we can write an
application that expects a particular server queue to be ready and
bound, and which will simply process messages off that queue.

However, we also allow AMQ client applications to:

 - create or destroy server queues
 - define the way these queues are filled, by making bindings

This is like having an email system where one can, via the protocol:

 - create a new mailbox.
 - tell the MTA that all messages with a specific header field should
   be copied into this mailbox.

We see that AMQ is more like a language for wiring pieces together than
a system. This is part of our objective, to make the server behaviour
programmable via the protocol.

Automatic Mode
..............

Most integration architectures do not need this sophistication. Like the
amateur photographer, a majority of AMQ users need a "point and shoot"
mode.  AMQ provides this through the use of two simplifying concepts:

 1. A default exchange for message producers.

 2. A default binding for server queues that selects messages based on
    a match between routing key and queue name.

In effect, the default binding lets a producer send messages directly to
a queue, given suitable authority. The default binding does not prevent
the queue from being used in more sophisticated ways. It does, however,
let one use AMQ without needing to understand how exchanges and bindings
work.

Exchanges
---------

Types of Exchange
.................

Each exchange type implements a specific routing algorithm. There are a
number of standard exchange types, explained in the "Functional
Specifications" chapter, but there are two that are particularly
important:

 - the "direct" exchange type, which routes on a routing key,
 - the "topic" exchange type, which routes on a routing pattern.

Note that:

 1. The default exchange is a direct exchange.

 2. The server will create a named direct and topic exchange
    automatically, in each vhost.

Exchange Lifecycle
..................

Each AMQ server pre-creates a number of exchanges.  These exchanges exist
when the server starts and cannot be destroyed.

AMQ applications can also create their own exchanges. AMQ does not use a
"create" method as such, it uses a "declare" method which means, "create
if not present, otherwise continue". It is plausible that applications
will create exchanges for private use and destroy them when their work
is finished. AMQ provides a method to destroy exchanges but in general
applications do not do this.

In our examples in this chapter we will assume that the exchanges are
all created by the server at startup. We will not show the application
declaring its exchanges.

Server Queues
-------------

Queue Properties
................

When a client application creates a queue, it can select some important
properties:

 - name - if left unspecified, the server choses a name and provides this
   to the client. Generally, when applications share a queue they agree
   on a queue name beforehand, and when an application needs a queue for
   its own purposes, it lets the server provide a name.

 - durable - if specified, the queue remains active when the server
   restarts.

 - auto-delete - If specified, the queue is deleted when all clients have
   finished using it.

Queue Lifecycles
................

There are two main queue lifecycles:

 - Durable queues that are shared by many consumers and have an indendent
   existence. I.e. they will continue to exist and collect messages whether
   or not there are consumers to receive them.

 - Temporary queues that are private to one consumer and are tied to that
   consumer. When the consumer disconnects, the queue is deleted.

There are some variations on these, such as shared queues that are
deleted when the last of many consumers disconnects.

This diagram shows the way temporary queues are created and deleted:

                                Queue
                              +-------+
                    Declare   +-------+  Queue is created
                    --------> +-------+
    +-------------+           +-------+
    |  Consumer   | Consume
    | application | -------->
    +-------------+           \ Queue  /
                    Cancel    +\\----/*
                    --------> +--\\//-+  Queue is deleted
                              +--//\\-+
                              +//----\*
                              /        \

Bindings
--------

A binding is the relationship between an exchange and a server queue
that tells the exchange how to route messages. Bindings are constructed
from commands from the client application (the one owning and using the
queue) to an exchange. We can express a binding command in pseudo-code
as follows:

    Queue.Bind <queue> TO <exchange> WHERE <condition>

Let's look at three typical use cases: named queues, private reply
queues, and pub-sub subscriptions.

Constructing a Named Queue
..........................

Named queues are the classic middleware "point to point queue". In AMQ
we can use the default exchange and default binding. Let's assume our
queue is called "app.svc01". Here is the pseudo-code for creating the
queue:

    Queue.Create
        queue=app.svc01
        private=FALSE

We may have many consumers on this queue. To consume from the queue,
each consumer does this:

    Jms.Consume
        queue=app.svc01

To publish to the queue, each producer sends a message to the default
exchange:

    Jms.Publish
        routing_key=my.svc01

Constructing a Reply Queue
..........................

Reply queues are usually temporary, with server-assigned names. They are
also usually private, i.e. read by a single consumer. Apart from these
particularities, reply queues use the same matching criteria as standard
queues, so we can also use default exchange.

Here is the pseudo-code for creating a reply queue, where S: indicates a
server reply:

    Queue.Create
        queue=<empty>
        private=TRUE
        auto_delete=TRUE
    S:Queue.Create-Ok
        queue=tmp.1

To publish to the reply queue, a producer sends a message to the default
exchange:

    Jms.Publish
        routing_key=tmp.1

One of the standard message properties is Reply-To, which is designed
specifically for carrying the name of reply queues.

Constructing a Pub-Sub Subscription Queue
.........................................

In classic middleware the term "subscription" is vague and refers to at
least two different concepts: the set of criteria that match messages
and the temporary queue that holds matched messages. AMQ separates the
work into into bindings and server queues. There is no AMQ entity called
"subscription".

Let us agree that a pub-sub subscription:

 - holds messages for a single consumer (or in some cases for multiple
   consumers).

 - collects messages from multiple sources, through a set of bindings
   that match topics, message fields, or content in different ways.

The key difference between a subscription queue and a named or
reply queue is that the subscription queue name is irrelevant for
the purposes of routing, and routing is done on abstracted matching
criteria rather than a 1-to-1 matching of the routing key field.

Let's take a common pub-sub model - topic trees - and implement this. We
need an exchange type capable of matching on a topic tree. In AMQ this
is the "topic" exchange type. The topic exchange matches wildcards like
"STOCK.USD.*" against routing key values like "STOCK.USD.NYSE".

We cannot use the default exchange or binding because these do not do
topic-style routing. So we have to create a binding explicitly. Here is
the pseudo-code for creating and binding the pub-sub subscription queue:

    Queue.Create
        queue=<empty>
        auto_delete=TRUE
    S:Queue.Create-Ok
        queue=tmp.2
    Queue.Bind
        queue=tmp.2
        TO exchange=amq.topic
        WHERE routing_key=STOCK.USD.*

To consume from the queue, the consumer does this:

    Jms.Consume
        queue=tmp.2

When publishing a message, the producer does something like this:

    Jms.Publish
        exchange=amq.topic
        routing_key=STOCK.USD.IBM

The topic exchange processes the incoming routing key ("STOCK.USD.IBM")
with its binding table, and finds one match, for tmp.2. It then routes
the message to that queue.

Chained Bindings
................

The basic structures explained above are enough to implement standard
queues and standard pub-sub topics. However, some applications need more
than this: they need to be able to combine matching algorithms so that
messages are matched several times before they reach a client
application.

We want to provide the following semantic:

    Queue.Bind <queue> TO <exchange1> WHERE <condition>
                   AND TO <exchange2> WHERE <condition>

Note that the "OR" semantic is trivial, we simply make two separate
bindings for the same queue. It is the "AND" semantic that is delicate.

For performance reasons, AMQP does not provide an actual language in
which to express such semantics. Rather we will construct the combined
semantic from individual methods:

    Queue.Bind <queue> TO <exchange1> WHERE <condition>
    Queue.Bind <queue> TO <exchange2> VIA <exchange1> WHERE <condition>

We call this a "chained binding". To see how this would work in
practice, let's take two such algorithms as examples: one is "topic",
which matches the routing key against a wildcard pattern, and the other
is "filter", which detects illegally large or otherwise dangerous
messages. (Note, "filter" is not real, just an example.) We have two
exchange instances, amq.topic and amq.filter.

We want to match all messages with routing key like "STOCK.USD.*" and
which have a PDF file in their content (one of the abilities of the
imaginary filter exchange is to filter according to the content types of
messages).

We create a temporary queue and bind it as follows:

    Queue.Create
        queue=<empty>
        auto_delete=TRUE
    S:Queue.Create-Ok
        queue=tmp.3
    Queue.Bind
        queue=tmp.3
        TO exchange=amq.topic
        WHERE routing_key=STOCK.USD.*
    Queue.Bind
        queue=tmp.3
        TO exchange=amq.filter
        VIA exchange=amq.topic
        WHERE content-type=application/x-pdf

To publish a message, we send to the amq.topic as before:

    Jms.Publish
        exchange=amq.topic
        routing_key=STOCK.USD.IBM
        content-type=application/x-pdf

Significance of Wiring Order
............................

When we make chained bindings, we get an ordered graph of exchanges
starting with the "root" exchange to which the producer sends the
messages.

Functionally, these two sets of statements are equivalent:

    Queue.Bind <queue> TO <exchange1> WHERE <condition>
    Queue.Bind <queue> TO <exchange2> VIA <exchange1> WHERE <condition>

and:

    Queue.Bind <queue> TO <exchange2> WHERE <condition>
    Queue.Bind <queue> TO <exchange1> VIA <exchange2> WHERE <condition>

That is, chained bindings are like the Boolean AND operator, where order
has no effect on the output result. However, order does have an effect
on the internal processing flow and thus the performance. In general
messages should pass through the most selective exchanges first.

In most pub-sub scenarios it would make sense to use a topic exchange as
the main exchange, and then use topics as a primary selection mechanism
for messages.

Note that the current protocol specifications do not implement chained
binding semantics.

Late Bindings
.............

Applications need to be able to select messages from queues, at the same
time as consuming them. While this is not efficient (it usually means
scanning messages sequentially), it is a common requirement because it
is conceptually simple and similar in some ways to the SQL SELECT
statement.  AMQ must therefore support this.

We call this a "late binding". We can compare this to a normal binding:

- A normal binding routes messages into a server queue after which they
  are dispatched to N consumers on a round-robin basis. For example,
  we may route print jobs to different queues based on where the printed
  documents must go.

- The select-on-consume semantic works on a single server queue for N
  consumers, but where each consumer may have an independent set of
  criteria for the messages it wants to process. For example, one of a
  group of printers servicing a single print queue might ask to receive
  all oversized documents, by preference.

The main difference is that (a) the round-robin nature of message
delivery remains in force, so if multiple consumers have the same late
binding criteria, they will share the messages, and (b) the delivery of
messages remains ordered. Using normal bindings, this is not possible.

So late bindings apply when the server searches for a consumer for the
next message. They are inherently slower than normal bindings, because a
message will be matched multiple times rather than just once.

We can express a late binding command in pseudo-code as follows:

    Jms.Consume FROM <queue> WHERE <condition>

Note that the current protocol specifications do not implement late
binding semantics.

AMQP Functional Design
======================

This section explains how the application talks to the server.

The Class/Method Model
----------------------

Middleware is complex, and our challenge in designing the protocol
structure was to tame that complexity. Our approach has been to model a
traditional API based on classes and methods, and to define methods to
do exactly one thing, and do it well. This results in a large command
set but one that is easy to understand.

The AMQP commands are grouped into classes. Each class covers a specific
functional domain. Some classes are optional - each peer implements the
classes it needs to support.

There are two distinct types of method:

 - Synchronous methods, in which one peer sends a request and the other
   peer sends a reply.  Synchronous methods are used in most cases.

 - Asynchronous methods, in which one peer sends a command but expects
   no reply. Asynchronous methods where performance is critical.

To make method processing simple, we define distinct replies for each
synchronous request. That is, no method is used as the reply for two
different requests. This means that a peer, sending a synchronous
request, can accept and process incoming methods until getting one of
the valid synchronous replies.

A method is formally defined as a synchronous request, a synchronous
reply (to a specific request), or asynchronous.  Lastly, each method
is formally defined as being client-side (i.e. server to client), or
server-side (client to server).

Mapping AMQP to a middleware API
--------------------------------

We have designed AMQP to be mappable to a middlware API. This mapping
has some intelligence (not all methods, and not all arguments make sense
to an application) but it is also mechanical (given some rules, all
methods can be mapped without manual intervention).

The advantages of this are that having learnt the AMQP semantics (the
classes that are described in this section), developers will find the
same semantics provided in whatever environment they use.

For example, here is a Queue.Create method example:

    Queue.Create
        queue=my.queue
        auto_delete=TRUE
        exclusive=FALSE

This can be cast as a wire-level frame:

     +--------+--------+----------+---------+---------+
     | Queue  | Create | my.queue |    1    |    0    |
     +--------+--------+----------+---------+---------+
       class    method    name      autodel     excl.

Or as a high-level API:

    queue_create (session, "my.queue", TRUE, FALSE);

Or as an abstract language:

    <queue_create name = "my.queue" auto_delete = "1" exclusive = "FALSE" />

There are two main exceptions to making the entire protocol isomorphic
with the client API:

 1. Existing API standards, such as JMS, which must be mapped manually
    onto the AMQP methods.

 2. Those AMQP methods concerned with connection and session startup
    and shutdown, which are not useful to expose in the high-level API.

The pseudo-code logic for mapping an asynchronous method is:

    send method to server

The pseudo-code logic for mapping a synchronous method is:

    send request method to server
    repeat
        wait for response from server
        if response is an asynchronous method
            process method (usually, delivered or bounced content)
        else
            assert that method is a valid response for request
            exit repeat
        end-if
    end-repeat

It is worth commenting that for most applications, middleware can be
completely hidden in technical layers, and that the actual API used
matters less than the fact that the middleware is robust and fast.

No Confirmations
----------------

A chatty protocol is slow. We use asynchronicity heavily in those cases
where performance is an issue. This is generally where we send content
from one peer to another. We send off methods as fast as possible,
without waiting for confirmations. Where necessary, we can implement
windowing and throttling at a higher level.

We can dispense with confirmations because we adopt an assertion model
for all actions. Either they succeed, or we have an exception that
closes the channel or connection.

There are no confirmations in AMQP. Success is silent, and failure is
noisy. When applications need explicit tracking of success and failure,
they use transactions.

The Connection Class
--------------------

AMQP/Fast is a connected protocol.  The connection is designed to be
long-lasting, and can carry multiple channels.  The connection
life-cycle is this:

 - The client opens a TCP/IP connection to the server and sends a
   protocol header.  This is the only data the client sends that is
   not formatted as a method.

 - The server responds with its protocol version and other properties,
   including a list of the security mechanisms that it supports (the
   Start method).

 - The client selects a security mechanism (Start-Ok).

 - The server starts the authentication process, which uses the SASL
   challenge-response model.  It sends the client a challenge (Secure).

 - The client sends an authentication response (Secure-Ok). For example
   using the "plain" mechanism, the response consist of a login name and
   password.

 - The server repeats the challenge (Secure) or moves to negotiation,
   sending a set of parameters such as maximum frame size (Tune).

 - The client accepts or lowers these parameters (Tune-Ok).

 - The client formally opens the connection and selects a virtual host
   (Open).

 - The server confirms that the virtual host is a valid choice (Open-Ok).

 - The client now sends uses the connection as desired.

 - One peer (client or server) ends the connection (Close).

 - The other peer hand-shakes the connection end (Close-Ok).

 - The server and the client close their socket connection.

The Channel Class
-----------------

AMQP is a multi-channeled protocol. Channels are independent threads
of control that share a connection.  The channel life-cycle is this:

 - The client opens a new channel (Open).

 - The server confirms that the new channel is ready (Open-Ok).

 - The client and server use the channel as desired.

 - One peer (client or server) closes the channel (Close).

 - The other peer hand-shakes the channel close (Close-Ok).

The Access Class
----------------

AMQP's access control model is based on "realms". A realm covers some
group of server resources (exchanges and queues) managed under a single
security policy and access control. Applications ask for access to
specific realms, rather than to specific resources. The server grants
access in the form of "tickets", which the client application then uses
accordingly. Tickets expire when the channel is closed, or if the
server's access controls change.

The access ticket life-cycle is:

 - The client requests an access ticket for a realm (Request).

 - The server grants it (Request-Ok).

The server can, of course, refuse the request.

The Exchange Class
------------------

The exchange class lets an application manage exchanges on the server.
Most applications never do this but when it's necessary, this class lets
the application script its own wiring (rather than relying on some
configuration interface).  The exchange life-cycle is:

 - The client asks the server to make sure the exchange exists
   (Declare). The client can refine this into, "create the exchange if
   it does not exist", or "warn me but do not create it, if it does not
   exist".

 - The client publishes messages to the exchange.

 - The client may choose to delete the exchange (Delete).

The Queue Class
---------------

The queue class lets an application manage queues on the server. This is
a basic step in almost all applications that consume messages, at least
to verify that an expect queue is actually present.

The life-cycle for a durable queue is fairly simple:

 - The client asserts that the queue exists (Declare, with the "passive"
   argument).

 - The server confirms that the queue exists (Declare-Ok).

 - The client reads messages off the queue.

The life-cycle for a temporary queue is more interesting:

 - The client creates the queue (Declare, often with no queue name so
   the server will assign a name).  The server confirms (Declare-Ok).

 - The client starts a consumer on the queue. See the content classes.

 - The client cancels the consumer, either explicitly or by closing the
   channel and/or connection.

 - When the last consumer disappears from the queue, and after a polite
   timeout, the server deletes the queue.

Topic subscriptions are also queues. That is, AMQ implements topic
subscriptions as server queues. The life-cycle for a subscription
involves an extra bind stage:

 - The client creates the queue (Declare), and the server confirms
   (Declare-Ok).

 - The client binds the queue to a topic exchange (Bind) and the server
   confirms (Bind-Ok).

 - The client uses the queue as in the previous examples.

The Content Classes
-------------------

Following the principle of placing functional domains into distinct
protocol classes that the server may or may not implement, AMQP also
separates content processing into separate classes. The logic is that
different types of content have different semantics. For example, JMS
messages and file transfer are quite different problems.  We give
each content type a class, and a set of methods that work with it.

AMQP currently defines four content classes:

 1. JMS contents, which support the JMS semantics.

 2. Basic contents, which have the simplest possible semantics for
    a message-oriented usable middleware system.

 3. File contents, which support file-transfer semantics.

 4. Stream contents, which support data streaming semantics.

The JMS Content Class
.....................

The JMS content class is designed to map cleanly to the JMS API.  It
has the same properties as a JMS message (priority, expiration, etc.)
and supports the JMS API.

The JMS content methods support these main semantics:

 - Sending messages from client to server, which happens asynchronously
   (Publish).

 - Starting and stopping consumers (Consume, Cancel).

 - Sending messages from server to client, which happens asynchronously
   (Deliver, Bounce).

 - Acknowledging messages (Ack, Reject).

 - Taking messages off the queue synchronously (Get).

The Basic Content Class
.......................

The basic content class is designed to provide minimalistic usable
messaging semantics. This permits the development of simple AMQ servers
for cases when full JMS semantics (the conventional need) are not
necessary. We also use the basic content class to access system services
(like the AMQ Console, which is documented elsewhere).

The basic content methods support these main semantics:

 - Sending messages from client to server, which happens asynchronously
   (Publish).

 - Starting and stopping consumers (Consume, Cancel).

 - Sending messages from server to client, which happens asynchronously
   (Deliver, Bounce).

 - Taking messages off the queue synchronously (Get).

Compared to JMS, the basic content class has these simplifications:

 - Messages are not acknowledged - as soon as they are delivered to
   a consumer, they are removed from the queue.

 - Basic contents are not subject to transactions.

 - Basic contents have a more limited set of properties.

The File Content Class
......................

The file content class is designed for file transfer. It has specific
support for restarting incomplete file transfers. We do this by sending
file messages in two steps:

 1. The sender uploads the file to the recipient. We call this "staging".
    If the upload is interrupted, the sender can recover and send only
    the missing part of the file.

 2. The sender tells the recipient to process the file (e.g. to publish
    it).

The file content methods support these main semantics:

 - Staging a file, from either peer to the other (Open, Stage).

 - Sending a staged file from client to server, which happens
   asynchronously (Publish).

 - Starting and stopping consumers (Consume, Cancel).

 - Sending messages from server to client, which happens asynchronously
   (Deliver, Bounce).

 - Acknowledging messages (Ack, Reject).

The Stream Content Class
........................

The stream content class is designed for content streaming (voice,
video, etc.)  It has these main semantics:

 - Sending messages from client to server, which happens asynchronously
   (Publish).

 - Starting and stopping consumers (Consume, Cancel).

 - Sending messages from server to client, which happens asynchronously
   (Deliver, Bounce).

The power of the stream content class lies in the consumer
specification, which is much more focussed on the quality of service
(with parameters such as desired transfer rate in octets per second)
than consumers in other classes.

The Transaction Class
---------------------

AMQP supports three kinds of transactions:

1. Automatic transactions, in which every published message and
   acknowledgement is processed as a stand-alone transaction.

2. Server transactions, in which the server will buffer published
   messages and acknowledgements and commit them on demand from the
   client.

3. XA 2-phase transactions, in which the server will synchronise
   its transactions with an external transaction coordinator.

The transaction class ("tx") gives applications access to the second
type, namely server transactions.  The semantics of this class are:

 - The application asks for server transactions in each channel where
   it wants these transactions (Select).

 - The application does work (Publish, Ack).

 - The application commits or rolls-back the work (Commit, Rollback).

 - The application does work, ad infinitum.

The Distributed Transaction Class
---------------------------------

The distributed transaction class ("dtx") provides simpler semantics
because most of the work is done by the server and external transaction
coordinator behind the scenes.

The semantics of this class are as follows:

 - The application asks for server transactions in each channel where
   it wants these transactions (Select).

 - The application does work (Publish, Ack).

 - Magic happens.

AMQP Transport Layer
====================

This section explains how the wire-level protocol (AMQP/Fast) works.

General Description
-------------------

AMQP/Fast is a binary protocol. Information is organised into "frames",
of various types. Frames carry protocol methods, structured contents,
and other information. All frames have the same general format: header
plus payload. The frame payload format depends on the frame type.

We assume a reliable stream-oriented network transport layer (TCP/IP or
equivalent).

Within a single socket connection, there can be multiple independent
threads of control, called "channels". Each frame is numbered with a
channel number. By interleaving their frames, different channels share
the connection. For any given channel, frames run in a strict sequence
that can be used to drive a protocol parser (typically a state machine).

We construct frames using a small set of data types such as bits,
integers, strings, and field tables. Frame fields are packed tightly
without making them slow or complex to parse. It is relatively simple to
generate framing layer mechanically from the protocol specifications.

The wire-level formatting is designed to be scalable and generic enough
to be used for arbitrary high-level protocols (not just AMQP). We assume
that AMQP will be extended over time, and that manufacturers will want
to make variations and derivative protocols, and the wire-level format
will support this.

Data Types
----------

The AMQP/Fast data types are:

 - Integers (from 1 to 8 octets), used to represent sizes, quantities,
   limits, etc. Integers are always unsigned and may be unaligned within
   the frame.

 - Bits, used to represent on/off values. Bits are packed into octets.

 - Short strings, used to hold short text properties. Short strings are
   limited to 255 octets and can be parsed with no risk of buffer
   overflows.

 - Long strings, used to hold chunks of binary data.

 - Field tables, which hold name-value pairs. The field values are
   typed as strings, integers, etc.

Protocol Negotiation
--------------------

The AMQP/Fast client and server negotiate the protocol. This means that
when the client connects, the server proposes certain options that the
client can accept, or modify. When both peers agree on the outcome, the
connection goes ahead. Negotiation is a useful technique because it lets
us assert assumptions and preconditions.

In AMQP/Fast, we negotiate a number of specific aspects of the protocol:

 1. The actual protocol and version. An AMQP/Fast server can host
    multiple protocols on the same port.

 2. Encryption arguments and the authentication of both parties. This is
    part of the functional layer, explained previously.

 3. Maximum frame size, number of channels, and other operational
    limits.

Agreed limits allow both parties to pre-allocate key buffers, avoiding
deadlocks. Every incoming frame either obeys the agreed limits, so is
"safe", or exceeds them, in which case the other party is faulty and can
be disconnected. Both peers negotiate the limits to the lowest agreed
value as follows:

 1. The server tells the client what limits it proposes.

 2. The client can respond to lower the limits for its connection.

Delimiting Frames
-----------------

TCP/IP is a stream protocol, i.e. there is no in-built mechanism for
delimiting frames. Existing protocols solve this in several different
ways:

- Sending a single frame per connection. This is simple but slow.

- Adding frame delimiters to the stream. This is simple but slow to
  parse.

- Counting the size of frames and sending the size in front of each
  frame. This is simple and fast, and our choice.

Frame Details
-------------

All frames consist of a header (8 octets), a payload of arbitrary size, and
a 'frame-end' octet that detects malformed frames:

    0      1       2         4             8               size+8
    +------+-------+---------+----------+  +------------+  +-----------+
    | type | cycle | channel |   size   |  |  payload   |  | frame-end |
    +------+-------+---------+----------+  +------------+  +-----------+
     octet   octet    short      long       size-1 octets      octet

To read a frame, we:

 1. Read the header and check the frame type and channel.

 2. Depending on the frame type, we read the payload and process it.

 3. Read the frame end octet.

In realistic implementations where performance is a concern, we would
use read-ahead buffering to avoid doing three separate system calls to
read a frame.

Method Frames
.............

Method frames carry the high-level protocol commands (which we call
"methods"). One method frame carries one command. The method frame
payload has this format:

    0          2           4
    +----------+-----------+-------------- - -
    | class-id | method-id | arguments...
    +----------+-----------+-------------- - -
       short      short    ...

To process a method frame, we:

 1. Read the method frame payload.

 2. Unpack it into a structure.  A given method always has the same
    structure, so we can unpack the method rapidly.

 3. Check that the method is allowed in the current context.

 4. Check that the method arguments are valid.

 5. Pass the method to another layer for actual processing.

Method frame bodies are constructed as a list of AMQP data fields (bits,
integers, strings and string tables). The marshalling code is trivially
generated directly from the protocol specifications, and can be very
rapid.

Content Frames
..............

Content is the application data we carry from box to box. Content is,
roughly speaking, a set of properties plus a binary data part. The set
of allowed properties are defined by the content class, and these form
the "content header frame". The data can be any size, and can be broken
into several (or many) chunks, each forming a "content body frame".

Looking at the frames for a specific channel, as they pass on the wire,
we might see something like this:

    [method]
    [method] [header] [body] [body]
    [method]
    ...

Certain methods (such as Jms.Publish, Jms.Deliver, etc.) are formally
defined as carrying content. When a peer sends such a method frame, it
always follows it with a content header and zero or more content body
frames.

A content header frame has this format:

    0          2        4           12               14
    +----------+--------+-----------+----------------+------------- - -
    | class-id | weight | body size | property flags | property list...
    +----------+--------+-----------+----------------+------------- - -
       short     short    long long       short        remainder...

We place content body in distinct frames (rather than including it in
the method) so that AMQP/Fast supports "zero copy" techniques in which
content is never marshalled or encoded, and can be sent via out-of-band
transport such as shared memory or remote DMA.

We place the content properties in their own frame so that recipients
can selectively discard contents they do not want to process.

Contents can be structured with sub-contents to any level.

Out-of-band Frames
..................

Out-of-band transport can be used in specific high-performance models.
Note that this part of the protocol is speculative because we have not
built a working out-of-band prototype. This part of the protocol is a
placeholder rather than a formal proposal.

The principle of out-of-band transport is that a TCP/IP connection can
be used for controlling another, faster but less abstract protocol such
as remote-DMA, shared memory, or multicast.

Heartbeat Frames
................

Hearbeating is a technique designed to undo one of TCP/IP's features,
namely its ability to recover from a broken physical connection by
closing only after a quite long timeout. In some scenarios we need to
know very rapidly if a peer is disconnected or not responding for other
reasons (e.g. it is looping). Since heartbeating can be done at a low
level, we implement this as a special type of frame that peers exchange
at the transport level, rather than as a class method.

Connection Failover
-------------------

We provide a mechanism that lets a client reconnect to a server if there
is some temporary network failure, e.g. a connection across a fire-wall
being reset. Connection failover is fairly complex and is optional -
clients do not need to implement it.

This works as follows. When the client has connected and authenticated
itself, the server issues it with a "context key". A client that starts
a new connection requests a new context key from the server, and then
proceeds to open and use channels and create other server-side state.

After a connection failure, the server holds open the connection and its
server-side state for a period of time - e.g. one minute. During that
time, the client may reconnect and estabish a new connection. When the
client has established the connection, rather than requesting a new
context key, it provides the server with the old key. The server
verifies that this refers to a suspended connection and if so, transfers
the state from that old connection to the new connection.

The client holds its state in memory during this process, so that it can
equally transfer its open channels, etc. to the new connection.

Since network errors can cause methods to be lost, the two peers
exchange some information to allow them to get their state back to where
it was before the problem.

Assuming this is handled in some client API layer, the entire process is
invisible to applications.

Error Handling
--------------

AMQP uses exceptions to handle errors.  That is:

 - Any operational error, e.g. queue not found, insufficient access
   rights, etc. results in a channel exception.

 - Any structural error, e.g. invalid argument, bad sequence of methods,
   etc. results in a connection exception.

An exception closes the channel or connection, and returns a reply code
and reply text to the client application. We use the 3-digit reply code
plus textual reply text scheme that is used in HTTP and many other
protocols.

Closing Channels and Connections
--------------------------------

Closing a channel or connection for any reason - normal or exceptional -
must be done carefully. Abrupt closure is not always detected rapidly,
and following an exception, we could lose the error reply codes. The
correct design is to hand-shake all closure so that we close only after
we are sure the other party is aware of the situation.

When a peer decides to close a channel or connection, it sends a Close
method. The receiving peer responds with Close-Ok, and then both parties
can close their channel or connection.

AMQP Client Architecture
========================

It is possible to read and write AMQP frames directly from an
application but this would be bad design. Even the simplest AMQP
dialogue is rather more complex than e.g. HTTP, and application
developers should not need to understand such things as binary framing
formats in order to send a message to a queue.

The recommended AMQP client architecture consists of several layers
of abstraction:

1. A framing layer.  This layer takes AMQP protocol methods, in some
   language-specific format (structures, classes, etc.) and serialises
   them as wire-level frames.  The framing layer can be mechanically
   generated from the AMQP specifications (which are defined in an XML
   language, ASL, specifically designed for this).

2. A connection manager layer. This layer reads and writes AMQP frames
   and manages the overall connection and session logic. In this layer
   we can encapsulate the full logic of opening a connection and
   session, error handling, content transmission and reception, and so
   on.  Large parts of this layer can be produced automatically from the
   AMQP specifications. For instance, the specifications define which
   methods carry content, so the logic "send method and then optionally
   send content" can be produced mechanically.

3. An API layer. This layer exposes a specific API for applications to
   work with. The API layer may imitate some existing standard, such as
   JMS, or may expose the high-level AMQP methods, making a mapping as
   described earlier in this section.  The AMQP methods are designed to
   make this mapping both simple and useful.  The API layer may itself
   be composed of several layers, e.g. a higher-level API constructed
   on top of the AMQP method API.

4. A transaction processing layer.  This layer drives the application
   by delivering it transactions to process, where the transactions
   are middleware messages.  Using a transaction layer can be very
   powerful because the middleware becomes entirely hidden, making
   applications easier to build, test, and maintain.

Additionally, there is usually some kind of I/O layer, which can be very
simple (synchronous socket reads and writes) or sophisticated (fully
asynchronous multithreaded i/o).

This diagram shows the overall recommended architecture (without layer
4, which is a different story):

        +------------------------+
        |      Application       |
        +-----------+------------+
                    |
        +------------------------+
    +---|      API Layer         |----Client API Layer-----+
    |   +-----------+------------+                         |
    |               |                                      |
    |   +------------------------+    +---------------+    |
    |   |   Connection Manager   +----+ Framing Layer |    |
    |   +-----------+------------+    +---------------+    |
    |               |                                      |
    |   +------------------------+                         |
    +---| Asynchronous I/O Layer |-------------------------+
        +-----------+------------+
                    |
                 -------
         - - - - Network - - - -
                 -------

In this document, when we speak of the "client API", we mean all the
layers below the application (i/o, framing, connection manager, and API
layers. We will usually speak of "the client API" and "the application"
as two separate things, where the application uses the client API to
talk to the middleware server.


